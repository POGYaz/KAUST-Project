# Jarir B2B Recommendation System

A production-ready recommendation system built with a modern two-stage machine learning pipeline. This system provides personalized product recommendations for B2B customers using advanced neural architectures and feature engineering.

## ğŸ¯ Overview

The recommendation system employs a sophisticated two-stage approach:

1. **Retriever Stage**: Two-Tower neural network with user and item embeddings to efficiently identify top candidate products
2. **Reranker Stage**: Multi-layer perceptron (MLP) with engineered features to precisely rank the final recommendations

This architecture balances computational efficiency with recommendation quality, making it suitable for production deployment.

## ğŸš€ Live Demo

**Option 1: Streamlit Cloud (Recommended)**
- Visit the live application: [Jarir B2B Recommendation System](https://jarir-project.streamlit.app/)
- No installation required - ready to use immediately

**Option 2: Local Development**
- Clone and run locally for development and customization

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Query    â”‚ -> â”‚   Two-Tower      â”‚ -> â”‚   MLP Reranker  â”‚
â”‚                 â”‚    â”‚   Retriever      â”‚    â”‚                 â”‚
â”‚ Customer ID +   â”‚    â”‚                  â”‚    â”‚ Features:       â”‚
â”‚ Preferences     â”‚    â”‚ Retrieves ~200   â”‚    â”‚ â€¢ Similarity    â”‚
â”‚                 â”‚    â”‚ candidates       â”‚    â”‚ â€¢ Popularity    â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚ â€¢ Price         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        v
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚ Top-K Products  â”‚
                                               â”‚ Ranked by       â”‚
                                               â”‚ Relevance       â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
KAUST-Project/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py          # Interactive web application
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ data/                     # Clean dataset (Parquet files)
â”‚   â”‚   â”œâ”€â”€ customers_clean.parquet
â”‚   â”‚   â”œâ”€â”€ items_clean.parquet
â”‚   â”‚   â”œâ”€â”€ interactions_clean.parquet
â”‚   â”‚   â””â”€â”€ *_id_map.parquet
â”‚   â”œâ”€â”€ retriever/                # Two-Tower model artifacts
â”‚   â”‚   â”œâ”€â”€ user_embeddings.npy
â”‚   â”‚   â”œâ”€â”€ item_embeddings.npy
â”‚   â”‚   â””â”€â”€ training_metrics.json
â”‚   â””â”€â”€ reranker/                 # MLP reranker artifacts
â”‚       â”œâ”€â”€ ranker_best.pt
â”‚       â””â”€â”€ training_metrics.json
â”œâ”€â”€ src/                          # Core ML modules
â”‚   â”œâ”€â”€ data/                     # Data processing & feature engineering
â”‚   â”œâ”€â”€ models/                   # Model architectures
â”‚   â”œâ”€â”€ training/                 # Training pipelines
â”‚   â”œâ”€â”€ inference/                # Inference utilities
â”‚   â””â”€â”€ evaluation/               # Metrics & evaluation
â”œâ”€â”€ configs/                      # YAML configuration files
â”œâ”€â”€ scripts/                      # Training & data preparation CLIs
â”œâ”€â”€ tests/                        # Unit tests
â””â”€â”€ requirements.txt              # Dependencies
```

## ğŸ› ï¸ Local Setup

### Prerequisites
- Python 3.10+
- 8GB+ RAM recommended
- Windows/macOS/Linux

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/POGYaz/KAUST-Project
cd KAUST-Project
```

2. **Create virtual environment**
```bash
python -m venv .venv

# Windows
.\.venv\Scripts\activate

# macOS/Linux
source .venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Verify model artifacts**
Ensure these files exist:
- `models/retriever/{user_embeddings.npy, item_embeddings.npy}`
- `models/reranker/ranker_best.pt`
- `models/data/*.parquet`

5. **Launch the application**
```bash
streamlit run app/streamlit_app.py
```

The app will be available at `http://localhost:8501`

## ğŸ“Š Features

### ğŸ¨ User Interface
- **Clean, professional design** with light/dark theme support
- **Customer selection** with smart search and profile insights
- **Real-time recommendations** with sub-second response times
- **Detailed explanations** for recommendation logic
- **Purchase history analysis** and behavioral insights

### ğŸ¤– Machine Learning
- **Two-Tower retriever** with 128-dimensional embeddings
- **Feature-rich reranker** with engineered signals
- **FAISS-powered** approximate nearest neighbor search
- **Comprehensive evaluation** with Recall@K, NDCG@K metrics

### ğŸ”§ Technical Features
- **Models-first architecture** for easy deployment
- **Automatic model compatibility** handling
- **Robust error handling** and fallback mechanisms
- **Performance monitoring** and debug information

## ğŸ“ˆ Performance Metrics

| Metric | Value | Description |
|--------|-------|-------------|
| Recall@10 | ~0.69 | Fraction of relevant items in top-10 |
| NDCG@10 | ~0.55 | Normalized discounted cumulative gain |
| Response Time | <1s | End-to-end recommendation latency |
| Model Size | ~50MB | Combined model artifacts |

## ğŸ”„ Training Pipeline (Optional)

For retraining or customization:

1. **Data preparation**
```bash
python scripts/prepare_data.py --config configs/data.yaml
```

2. **Train retriever**
```bash
python scripts/train_retriever.py --config configs/retriever.yaml
```

3. **Train reranker**
```bash
python scripts/train_reranker.py --config configs/reranker.yaml
```

All outputs are automatically saved to the `models/` directory.

## ğŸš€ Deployment

### Streamlit Community Cloud
1. Fork this repository
2. Connect to Streamlit Cloud
3. Deploy directly - no additional configuration needed

### Custom Infrastructure
- **Docker**: Use provided containerization (optional)
- **Cloud platforms**: AWS, GCP, Azure compatible
- **Requirements**: Python 3.10+, 2GB+ RAM, 1 CPU core

## ğŸ§ª Testing

Run the test suite:
```bash
pytest tests/ -v
```

## ğŸ› ï¸ Tech Stack

- **Core ML**: Python, PyTorch, NumPy, Pandas, scikit-learn
- **Data Processing**: PyArrow (Parquet), YAML configuration
- **Models**: Two-Tower neural retriever, MLP reranker with feature engineering
- **Search**: FAISS for approximate nearest neighbors (ANN)
- **UI/UX**: Streamlit with custom CSS, responsive design, light/dark themes
- **Development**: Rich logging, pytest testing, modular architecture
- **Deployment**: Models-first structure, Streamlit Community Cloud ready

## ğŸ” Troubleshooting

### Common Issues

**Missing model files**
- Verify all required files exist in `models/` directory
- Check file permissions and paths

**Model loading errors**
- Clear Streamlit cache: Settings â†’ Clear cache
- Restart the application

**Performance issues**
- Ensure sufficient RAM (8GB+ recommended)
- Check CPU usage during inference

**Import errors on Streamlit Cloud**
- The app automatically handles Python path configuration
- Verify all dependencies are in `requirements.txt`

## ğŸ¤ Contributing

**Yazan Alkamal** | Software Engineering at UQU
- Led design and development of two-tower recommendation architecture
- Architected production-ready Streamlit application with business-focused interface
- Implemented models-first deployment structure and compatibility solutions
- Contributed to ML pipeline optimization and comprehensive data analysis features
- Enhanced project architecture and streamlined development workflow
