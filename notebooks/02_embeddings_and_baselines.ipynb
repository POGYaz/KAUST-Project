{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee120523",
   "metadata": {},
   "source": [
    "# 02: Data Embeddings & Baseline Models\n",
    "\n",
    "This notebook covers:\n",
    "\n",
    "- **Configuration & Imports**: define data paths and evaluation settings\n",
    "- **Load Processed Data**: sequences, maps, and interaction tables\n",
    "- **Data Inspection**: peek at samples\n",
    "- **Create Interaction Matrices**:\n",
    "  - Build sparse user–item matrices from sequences\n",
    "  - Generate train/test splits for evaluation\n",
    "- **Define Baseline Models**:\n",
    "  - Popularity\n",
    "  - Item-based KNN\n",
    "  - User-based KNN\n",
    "  - Matrix Factorization (NMF)\n",
    "- **Evaluation Metrics**: Recall@K\n",
    "- **Train & Evaluate** each baseline\n",
    "- **Summarize & Save** results to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa8c9b-1815-4995-9cbe-b928798a1d3f",
   "metadata": {},
   "source": [
    "## 1. Configuration & Imports\n",
    "\n",
    "- Set file paths for processed data\n",
    "- Define evaluation parameters (K values, sample sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ded760d1-c2c8-4443-b1c3-53f42b98ea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths to processed data\n",
    "out_dir = Path('../data/processed/jarir/')\n",
    "seq_train_path = out_dir / 'sequences_train.parquet'\n",
    "seq_val_path   = out_dir / 'sequences_val.parquet'\n",
    "seq_test_path  = out_dir / 'sequences_test.parquet'\n",
    "item_map_path  = out_dir / 'item_id_map.parquet'\n",
    "cust_map_path  = out_dir / 'customer_id_map.parquet'\n",
    "\n",
    "# Evaluation config\n",
    "K_VALUES = [5, 10, 20]\n",
    "EVAL_SAMPLE_SIZE = 1000  # sample users for faster evaluation (None = all)\n",
    "\n",
    "# Random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Placeholder for baseline results\n",
    "baseline_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862bc289-038b-419c-aa95-9840483ca49d",
   "metadata": {},
   "source": [
    "## 2. Load Processed Data\n",
    "\n",
    "- Read train/val/test sequence tables\n",
    "- Read user & item mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe0a0d0-011f-4ce0-992e-25c8ccf687c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sequences and maps...\n",
      "Train seq: 1108 rows\n",
      "Val seq:   169 rows\n",
      "Test seq:  160 rows\n",
      "Items:     1735\n",
      "Users:     929\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading sequences and maps...\")\n",
    "seq_train = pd.read_parquet(seq_train_path, engine='fastparquet')\n",
    "seq_val   = pd.read_parquet(seq_val_path,   engine='fastparquet')\n",
    "seq_test  = pd.read_parquet(seq_test_path,  engine='fastparquet')\n",
    "item_map  = pd.read_parquet(item_map_path, engine='fastparquet')\n",
    "cust_map  = pd.read_parquet(cust_map_path, engine='fastparquet')\n",
    "print(f\"Train seq: {len(seq_train)} rows\")\n",
    "print(f\"Val seq:   {len(seq_val)} rows\")\n",
    "print(f\"Test seq:  {len(seq_test)} rows\")\n",
    "print(f\"Items:     {len(item_map)}\")\n",
    "print(f\"Users:     {len(cust_map)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf62513-fcd2-4f21-b522-891523675762",
   "metadata": {},
   "source": [
    "## 3. Data Inspection\n",
    "\n",
    "- View a few example rows from sequences, item_map, and cust_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47526814-146d-4ed2-a20f-d2f6c8b2f697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sequence row:\n",
      "   customer_id  user_idx         ts history_idx  pos_item_idx     country\n",
      "0     10018322         5 2024-03-07        9 10            11  0103-PLAZA\n",
      "1     10018322         5 2024-03-24     9 10 11            12  0103-PLAZA\n",
      "2     10018322         5 2024-04-30  9 10 11 12            13  0103-PLAZA\n",
      "\n",
      "Sample item map:\n",
      "      stock_code  item_idx\n",
      "0      RQ-CHB002         0\n",
      "1  ZQ-F27318BGLD         1\n",
      "2     NE-0230059         2\n",
      "\n",
      "Sample customer map:\n",
      "   customer_id  user_idx\n",
      "0        11949         0\n",
      "1        24811         1\n",
      "2        33097         2\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample sequence row:\")\n",
    "print(seq_train.head(3))\n",
    "print(\"\\nSample item map:\")\n",
    "print(item_map.head(3))\n",
    "print(\"\\nSample customer map:\")\n",
    "print(cust_map.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749e2650-9f04-4223-8266-733a1c918f26",
   "metadata": {},
   "source": [
    "## 4. Create Sparse Interaction Matrix\n",
    "\n",
    "- Build user–item matrix: history items weighted lower than positive event\n",
    "- Also prepare full interactions matrix for non-sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc771185-e637-41fb-9b04-d7f2e53ecab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix: (929, 1735), nz=1623\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def build_matrix_from_sequences(seq_df, n_users, n_items):\n",
    "    rows, cols, vals = [], [], []\n",
    "    for _, r in seq_df.iterrows():\n",
    "        u = int(r['user_idx'])\n",
    "        p = int(r['pos_item_idx'])\n",
    "        # positive event\n",
    "        rows.append(u); cols.append(p); vals.append(1.0)\n",
    "        # history events\n",
    "        if pd.notna(r['history_idx']) and r['history_idx']:\n",
    "            h = [int(x) for x in r['history_idx'].split()]\n",
    "            for item in h:\n",
    "                rows.append(u); cols.append(item); vals.append(0.5)\n",
    "    return csr_matrix((vals, (rows, cols)), shape=(n_users, n_items))\n",
    "\n",
    "n_users = len(cust_map)\n",
    "n_items = len(item_map)\n",
    "train_mat = build_matrix_from_sequences(seq_train, n_users, n_items)\n",
    "full_mat  = build_matrix_from_sequences(pd.concat([seq_train, seq_val, seq_test]), n_users, n_items)\n",
    "print(f\"Train matrix: {train_mat.shape}, nz={train_mat.nnz}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34104978-121a-4619-8cea-909463aae8f4",
   "metadata": {},
   "source": [
    "## 5. Prepare Train/Test Split\n",
    "\n",
    "- Remove validation interactions from training matrix for proper held-out evaluation\n",
    "- Collect test interactions list [(user, item)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b5e3a0-d20a-474d-b7c1-a8096737a891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 169 held-out test cases\n"
     ]
    }
   ],
   "source": [
    "test_interactions = []\n",
    "for _, r in seq_val.iterrows():\n",
    "    u, p = int(r['user_idx']), int(r['pos_item_idx'])\n",
    "    test_interactions.append((u, p))\n",
    "    train_mat[u, p] = 0\n",
    "print(f\"Prepared {len(test_interactions)} held-out test cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601a0fd8-93c7-4175-be54-14cae239bc43",
   "metadata": {},
   "source": [
    "## 6. Define Baseline Models\n",
    "\n",
    "- **Popularity**: rank by total interactions\n",
    "- **ItemKNN**: cosine similarity on item columns\n",
    "- **UserKNN**: cosine similarity on user rows\n",
    "- **Matrix Factorization**: NMF on dense matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b45d35-d287-460f-b5f0-bb8f9bf7cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Popularity:\n",
    "    def fit(self, mat):\n",
    "        self.pop = np.array(mat.sum(axis=0)).flatten()\n",
    "        return self\n",
    "    def recommend(self, u, k=10):\n",
    "        seen = mat[u].nonzero()[1]\n",
    "        scores = self.pop.copy(); scores[seen] = -1\n",
    "        return np.argsort(scores)[-k:][::-1]\n",
    "\n",
    "class ItemKNN:\n",
    "    def __init__(self, k=50): self.k = k\n",
    "    def fit(self, mat):\n",
    "        self.sim = cosine_similarity(mat.T)\n",
    "        return self\n",
    "    def recommend(self, u, k=10):\n",
    "        user_vec = mat[u].toarray().flatten()\n",
    "        seen = user_vec.nonzero()[0]\n",
    "        scores = np.zeros(mat.shape[1])\n",
    "        for i in seen:\n",
    "            top = np.argsort(self.sim[i])[-self.k:]\n",
    "            scores[top] += self.sim[i, top]\n",
    "        scores[seen] = -1\n",
    "        return np.argsort(scores)[-k:][::-1]\n",
    "\n",
    "class UserKNN:\n",
    "    def __init__(self, k=50): self.k = k\n",
    "    def fit(self, mat):\n",
    "        self.sim = cosine_similarity(mat)\n",
    "        return self\n",
    "    def recommend(self, u, k=10):\n",
    "        top_users = np.argsort(self.sim[u])[-(self.k+1):][::-1]\n",
    "        scores = np.zeros(mat.shape[1])\n",
    "        for v in top_users:\n",
    "            scores += mat[v].toarray().flatten()\n",
    "        seen = mat[u].nonzero()[1]; scores[seen] = -1\n",
    "        return np.argsort(scores)[-k:][::-1]\n",
    "\n",
    "class MFBaseline:\n",
    "    def __init__(self, n_f=50): self.n_f = n_f\n",
    "    def fit(self, mat):\n",
    "        dense = mat.toarray()\n",
    "        self.model = NMF(n_components=self.n_f, random_state=42)\n",
    "        self.W = self.model.fit_transform(dense)\n",
    "        self.H = self.model.components_\n",
    "        return self\n",
    "    def recommend(self, u, k=10):\n",
    "        scores = self.W[u].dot(self.H)\n",
    "        seen = train_mat[u].nonzero()[1]; scores[seen] = -1\n",
    "        return np.argsort(scores)[-k:][::-1]\n",
    "\n",
    "# bind mat for popularity\n",
    "mat = train_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e07e87a-b683-4cf8-802b-2665027f3d5f",
   "metadata": {},
   "source": [
    "## 7. Evaluation Function (Recall@K)\n",
    "\n",
    "- Compute Recall@K over held-out test_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "379621e1-d569-4a2a-bfdf-d86649869fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(recs, true_item):\n",
    "    return int(true_item in recs)\n",
    "\n",
    "def evaluate(model, k=10):\n",
    "    hits = []\n",
    "    for u, true in test_interactions:\n",
    "        recs = model.recommend(u, k)\n",
    "        hits.append(recall_at_k(recs, true))\n",
    "    return np.mean(hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7cf03-c2cb-46ee-9ea5-22456b80c833",
   "metadata": {},
   "source": [
    "## 8. Train & Evaluate Baselines\n",
    "\n",
    "- Fit each model on `train_mat`\n",
    "- Evaluate Recall@K for K in `K_VALUES`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc777afe-5593-42b4-8911-c7667ff18115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Results: {'Popularity': {'Recall@5': 0.0650887573964497, 'Recall@10': 0.09467455621301775, 'Recall@20': 0.1242603550295858}, 'ItemKNN': {'Recall@5': 0.0, 'Recall@10': 0.0, 'Recall@20': 0.011834319526627219}, 'UserKNN': {'Recall@5': 0.029585798816568046, 'Recall@10': 0.029585798816568046, 'Recall@20': 0.047337278106508875}, 'MatrixFactorization': {'Recall@5': 0.0, 'Recall@10': 0.005917159763313609, 'Recall@20': 0.005917159763313609}}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "# Popularity\n",
    "pop = Popularity().fit(train_mat)\n",
    "results['Popularity'] = {f'Recall@{k}': evaluate(pop, k) for k in K_VALUES}\n",
    "\n",
    "# ItemKNN\n",
    "itemknn = ItemKNN(k=50).fit(train_mat)\n",
    "results['ItemKNN'] = {f'Recall@{k}': evaluate(itemknn, k) for k in K_VALUES}\n",
    "\n",
    "# UserKNN\n",
    "userknn = UserKNN(k=50).fit(train_mat)\n",
    "results['UserKNN'] = {f'Recall@{k}': evaluate(userknn, k) for k in K_VALUES}\n",
    "\n",
    "# Matrix Factorization\n",
    "mf = MFBaseline(n_f=50).fit(train_mat)\n",
    "results['MatrixFactorization'] = {f'Recall@{k}': evaluate(mf, k) for k in K_VALUES}\n",
    "\n",
    "print(\"Baseline Results:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98e407f-bf6f-40f5-801d-dddc8f8e85cf",
   "metadata": {},
   "source": [
    "## 9. Summarize & Save Results\n",
    "\n",
    "- Choose best model at highest K\n",
    "- Write `baseline_results.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dc329a3-d55f-4318-9f01-01ba23d92686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved baseline results, best=Popularity Recall@20=0.1243\n"
     ]
    }
   ],
   "source": [
    "best = max(results.items(), key=lambda x: x[1][f'Recall@{K_VALUES[-1]}'])\n",
    "baseline_summary = {\n",
    "    'held_out_interactions': results,\n",
    "    'best_model': best[0],\n",
    "    'best_recall': best[1][f'Recall@{K_VALUES[-1]}']\n",
    "}\n",
    "with open(out_dir / 'baseline_results.json', 'w') as f:\n",
    "    json.dump(baseline_summary, f, indent=2)\n",
    "\n",
    "print(f\"Saved baseline results, best={best[0]} Recall@{K_VALUES[-1]}={best[1][f'Recall@{K_VALUES[-1]}']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363860f-512c-4c61-b28d-ec56a3893938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
