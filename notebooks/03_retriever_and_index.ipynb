{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77922aa6-6335-4516-9309-c87d05298c4f",
   "metadata": {},
   "source": [
    "# 03: Two-Tower Retriever\n",
    "\n",
    "This notebook implements and trains a Two-Tower retrieval model:\n",
    "\n",
    "1. **Configuration & Imports**: set hyperparameters and load libraries\n",
    "2. **Data Loading**: read sequences and maps from preprocessed data\n",
    "3. **Model Architecture**: define user and item towers\n",
    "4. **Dataset & DataLoader**: prepare PyTorch datasets and collators\n",
    "5. **Initialize & Compile**: instantiate model, optimizer, scheduler\n",
    "6. **Training Loop**: train with in-batch negatives and early stopping\n",
    "7. **Save Embeddings**: export trained user/item embeddings\n",
    "8. **Evaluation & Comparison**: compute Recall@K and compare to baselines\n",
    "9. **Results Persistence**: save training logs and final metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca517f8-b888-45d5-b624-e2b4d1de5b6e",
   "metadata": {},
   "source": [
    "## 1. Configuration & Imports\n",
    "\n",
    "- Define paths for input/output\n",
    "- Set model, training, and optimization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc6e5c7-8577-4916-a279-cecad5d937b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Paths\n",
    "OUT_DIR = Path('../data/processed/jarir/')\n",
    "SEQ_TRAIN = OUT_DIR / 'sequences_train.parquet'\n",
    "SEQ_VAL   = OUT_DIR / 'sequences_val.parquet'\n",
    "ITEM_MAP   = OUT_DIR / 'item_id_map.parquet'\n",
    "CUST_MAP   = OUT_DIR / 'customer_id_map.parquet'\n",
    "BASELINE_RESULTS = OUT_DIR / 'baseline_results.json'\n",
    "\n",
    "# Model & Training Config\n",
    "CFG = {\n",
    "    'd_model':256,\n",
    "    'batch_size':512,\n",
    "    'accum_steps':2,\n",
    "    'epochs':50,\n",
    "    'patience':6,\n",
    "    'lr':5e-4,\n",
    "    'weight_decay':1e-4,\n",
    "    'dropout':0.2,\n",
    "    'eval_topk':10,\n",
    "    'seed':42,\n",
    "    'k_neg':50,\n",
    "    'fixed_logit_scale':10.0\n",
    "}\n",
    "# Reproducibility\n",
    "torch.manual_seed(CFG['seed'])\n",
    "np.random.seed(CFG['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531b212-b1e7-449d-91fd-c9852b7522ab",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "- Load train/val sequences and id maps\n",
    "- Print dataset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "947daa09-3829-49b5-8781-207ee471fc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train sequences: 1108\n",
      "Val   sequences: 169\n",
      "# items: 1735, # users: 929\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "seq_train = pd.read_parquet(SEQ_TRAIN, engine='fastparquet')\n",
    "seq_val   = pd.read_parquet(SEQ_VAL,   engine='fastparquet')\n",
    "item_map  = pd.read_parquet(ITEM_MAP, engine='fastparquet')\n",
    "cust_map  = pd.read_parquet(CUST_MAP, engine='fastparquet')\n",
    "print(f\"Train sequences: {len(seq_train)}\")\n",
    "print(f\"Val   sequences: {len(seq_val)}\")\n",
    "print(f\"# items: {len(item_map)}, # users: {len(cust_map)}\")\n",
    "\n",
    "# Load baseline results for comparison later\n",
    "with open(BASELINE_RESULTS) as f:\n",
    "    baseline_results = json.load(f)['held_out_interactions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc0ab6e-1c8f-4ca1-a376-ad9f62fcb696",
   "metadata": {},
   "source": [
    "## 3. Two-Tower Model Architecture\n",
    "\n",
    "- Two MLP towers with embedding + LayerNorm + ReLU + Dropout\n",
    "- Normalize final vectors for cosine similarity scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539a9f94-7b2b-43cb-a7f0-d8d8b9c9ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, n_users, n_items, d_model, dropout):\n",
    "        super().__init__()\n",
    "        # Embeddings\n",
    "        self.user_emb = nn.Embedding(n_users, d_model)\n",
    "        self.item_emb = nn.Embedding(n_items, d_model)\n",
    "        # MLP towers\n",
    "        def make_tower():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(d_model, d_model), nn.LayerNorm(d_model), nn.ReLU(), nn.Dropout(dropout),\n",
    "                nn.Linear(d_model, d_model), nn.LayerNorm(d_model), nn.ReLU(), nn.Dropout(dropout)\n",
    "            )\n",
    "        self.user_mlp = make_tower()\n",
    "        self.item_mlp = make_tower()\n",
    "        # init\n",
    "        nn.init.normal_(self.user_emb.weight, 0, 0.1)\n",
    "        nn.init.normal_(self.item_emb.weight, 0, 0.1)\n",
    "    def user_vec(self, uids):\n",
    "        u = self.user_emb(uids); return F.normalize(self.user_mlp(u), p=2, dim=1)\n",
    "    def item_vec(self, iids):\n",
    "        v = self.item_emb(iids); return F.normalize(self.item_mlp(v), p=2, dim=1)\n",
    "    def forward(self, uids, pos_i, neg_i=None):\n",
    "        u_vec = self.user_vec(uids)\n",
    "        pos_vec = self.item_vec(pos_i)\n",
    "        pos_scores = (u_vec * pos_vec).sum(1) * CFG['fixed_logit_scale']\n",
    "        if neg_i is None:\n",
    "            return pos_scores\n",
    "        neg_vecs = self.item_vec(neg_i.view(-1)).view(uids.size(0), -1, u_vec.size(-1))\n",
    "        neg_scores = torch.sum(u_vec.unsqueeze(1) * neg_vecs, dim=2) * CFG['fixed_logit_scale']\n",
    "        return pos_scores, neg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab2f72-edf1-4c33-aefa-2ad1ab4d44e1",
   "metadata": {},
   "source": [
    "## 4. Dataset & DataLoader\n",
    "\n",
    "- Custom `Dataset` sampling `k_neg` negatives per example\n",
    "- Collate with padding for variable-length history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac651f6-9941-427d-9ef3-0b956eca6693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 3, Val batches: 1\n"
     ]
    }
   ],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, df, n_items, k_neg):\n",
    "        self.df = df; self.n_items = n_items; self.k_neg = k_neg\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        u = torch.tensor(int(row['user_idx']), dtype=torch.long)\n",
    "        pos = torch.tensor(int(row['pos_item_idx']), dtype=torch.long)\n",
    "        hist = []\n",
    "        if pd.notna(row['history_idx']): hist = [int(x) for x in row['history_idx'].split()]\n",
    "        # sample negatives\n",
    "        forbid = set(hist + [int(pos)])\n",
    "        avail = list(set(range(self.n_items)) - forbid)\n",
    "        neg = np.random.choice(avail, size=self.k_neg, replace=len(avail)<self.k_neg)\n",
    "        return {'user':u, 'pos':pos, 'neg':torch.tensor(neg, dtype=torch.long), 'hist':torch.tensor(hist, dtype=torch.long)}\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    users = torch.stack([b['user'] for b in batch])\n",
    "    pos   = torch.stack([b['pos'] for b in batch])\n",
    "    neg   = torch.stack([b['neg'] for b in batch])\n",
    "    hists = pad_sequence([b['hist'] for b in batch], batch_first=True, padding_value=-1)\n",
    "    mask  = (hists >= 0)\n",
    "    return {'user':users, 'pos':pos, 'neg':neg, 'hist':hists, 'mask':mask}\n",
    "\n",
    "# Create loaders\n",
    "train_ds = SequenceDataset(seq_train, len(item_map), CFG['k_neg'])\n",
    "val_ds   = SequenceDataset(seq_val,   len(item_map), CFG['k_neg'])\n",
    "train_loader = DataLoader(train_ds, batch_size=CFG['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=CFG['batch_size'], shuffle=False, collate_fn=collate_fn)\n",
    "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed94a3-0a33-4ca1-ad34-a8777ca28dbc",
   "metadata": {},
   "source": [
    "## 5. Initialize Model, Optimizer & Scheduler\n",
    "\n",
    "- Use `AdamW` and `ReduceLROnPlateau` on Recall@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1339bfd4-5556-44e7-bbce-6e0186349bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoTowerModel(len(cust_map), len(item_map), CFG['d_model'], CFG['dropout']).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "# Loss: in-batch negative sampling\n",
    "\n",
    "def in_batch_loss(pos_s, neg_s):\n",
    "    logits = torch.cat([pos_s.unsqueeze(1), neg_s], dim=1)\n",
    "    labels = torch.zeros(pos_s.size(0), dtype=torch.long, device=device)\n",
    "    return F.cross_entropy(logits, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea148d51-2856-4001-8e45-9270900fda2e",
   "metadata": {},
   "source": [
    "## 6. Training Loop\n",
    "\n",
    "- Train for up to `epochs`, early stop on validation Recall@K\n",
    "- Track training loss and validation Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bc54df7-2fdf-41f6-a3cd-057a06350a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=4.0241, Recall@10=0.0059\n",
      "Epoch 2: Loss=3.9228, Recall@10=0.0178\n",
      "Epoch 3: Loss=3.8927, Recall@10=0.0296\n",
      "Epoch 4: Loss=3.8334, Recall@10=0.0533\n",
      "Epoch 5: Loss=3.8122, Recall@10=0.0828\n",
      "Epoch 6: Loss=3.7632, Recall@10=0.0947\n",
      "Epoch 7: Loss=3.7373, Recall@10=0.1065\n",
      "Epoch 8: Loss=3.6646, Recall@10=0.1065\n",
      "Epoch 9: Loss=3.6348, Recall@10=0.1065\n",
      "Epoch 10: Loss=3.5969, Recall@10=0.1065\n",
      "Epoch 11: Loss=3.5321, Recall@10=0.1065\n",
      "Epoch 12: Loss=3.4783, Recall@10=0.1065\n",
      "Epoch 13: Loss=3.5307, Recall@10=0.1124\n",
      "Epoch 14: Loss=3.5071, Recall@10=0.1124\n",
      "Epoch 15: Loss=3.4558, Recall@10=0.1124\n",
      "Epoch 16: Loss=3.4055, Recall@10=0.1124\n",
      "Epoch 17: Loss=3.4233, Recall@10=0.1124\n",
      "Epoch 18: Loss=3.3313, Recall@10=0.1124\n",
      "Epoch 19: Loss=3.3434, Recall@10=0.1124\n",
      "Early stopping.\n",
      "Best validation Recall@10: 0.1124\n"
     ]
    }
   ],
   "source": [
    "best_recall = 0.0; patience_counter = 0\n",
    "train_losses = []; val_recalls = []\n",
    "for epoch in range(1, CFG['epochs']+1):\n",
    "    model.train(); total_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader, 1):\n",
    "        u = batch['user'].to(device)\n",
    "        p = batch['pos'].to(device)\n",
    "        n = batch['neg'].to(device)\n",
    "        pos_s, neg_s = model(u, p, n)\n",
    "        loss = in_batch_loss(pos_s, neg_s) / CFG['accum_steps']\n",
    "        loss.backward()\n",
    "        if i % CFG['accum_steps'] == 0:\n",
    "            optimizer.step(); optimizer.zero_grad()\n",
    "        total_loss += loss.item() * CFG['accum_steps']\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    # Validation\n",
    "    model.eval(); hits = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            u = batch['user'].to(device)\n",
    "            p = batch['pos'].to(device)\n",
    "            u_vec = model.user_vec(u)\n",
    "            all_items = torch.arange(len(item_map), device=device)\n",
    "            i_vecs = model.item_vec(all_items)\n",
    "            scores = u_vec @ i_vecs.T\n",
    "            topk = scores.topk(CFG['eval_topk'], dim=1).indices\n",
    "            hits.append((topk == p.unsqueeze(1)).any(1).float().mean().item())\n",
    "    val_recall = np.mean(hits); val_recalls.append(val_recall)\n",
    "    scheduler.step(val_recall)\n",
    "    print(f\"Epoch {epoch}: Loss={avg_loss:.4f}, Recall@{CFG['eval_topk']}={val_recall:.4f}\")\n",
    "    if val_recall > best_recall:\n",
    "        best_recall = val_recall; patience_counter = 0\n",
    "        torch.save(model.state_dict(), OUT_DIR/'best_twotower_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= CFG['patience']:\n",
    "            print(\"Early stopping.\"); break\n",
    "print(f\"Best validation Recall@{CFG['eval_topk']}: {best_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290ad58-f1c6-4baa-bfc7-30d0a1edad42",
   "metadata": {},
   "source": [
    "## 7. Save Embeddings\n",
    "\n",
    "- Generate and save all user and item embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e6e5d58-175f-4c37-a886-aa938295de92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings shapes: (929, 256), (1735, 256)\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(OUT_DIR/'best_twotower_model.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    users = torch.arange(len(cust_map), device=device)\n",
    "    items = torch.arange(len(item_map), device=device)\n",
    "    u_emb = model.user_vec(users).cpu().numpy()\n",
    "    i_emb = model.item_vec(items).cpu().numpy()\n",
    "    np.save(OUT_DIR/'user_embeddings.npy', u_emb)\n",
    "    np.save(OUT_DIR/'item_embeddings.npy', i_emb)\n",
    "print(f\"Saved embeddings shapes: {u_emb.shape}, {i_emb.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6200103b-e3fa-4546-b4dd-87f62168b99e",
   "metadata": {},
   "source": [
    "## 8. Evaluation & Comparison\n",
    "\n",
    "- Reload best model and compute final Recall@K\n",
    "- Compare to baselines loaded earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2537a9e5-086c-4bd6-9cf8-65c651402c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Tower Recall@10: 0.1124\n",
      "Best baseline    : 0.0947\n"
     ]
    }
   ],
   "source": [
    "# Final eval on validation (or test if available)\n",
    "model.eval(); hits = []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        u=batch['user'].to(device); p=batch['pos'].to(device)\n",
    "        u_vec=model.user_vec(u); scores=u_vec @ i_vecs.T\n",
    "        topk=scores.topk(CFG['eval_topk'],dim=1).indices\n",
    "        hits.append((topk==p.unsqueeze(1)).any(1).float().mean().item())\n",
    "final_recall = np.mean(hits)\n",
    "recall_key = f\"Recall@{CFG['eval_topk']}\"\n",
    "best_baseline = max(\n",
    "    baseline_results.items(),\n",
    "    key=lambda x: x[1][recall_key]\n",
    ")[1][recall_key]\n",
    "print(f\"Two-Tower Recall@{CFG['eval_topk']}: {final_recall:.4f}\")\n",
    "print(f\"Best baseline    : {best_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b3320-3837-4eaf-bd2a-2729e8aa5b49",
   "metadata": {},
   "source": [
    "## 9. Save Results\n",
    "\n",
    "- Persist model config, training curves, and comparison metrics to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20847ef6-8105-4484-acd0-84bfa12dcfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Two-Tower results to twotower_results.json\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    'model_config': CFG,\n",
    "    'training': {'train_losses': train_losses, 'val_recalls': val_recalls},\n",
    "    'best_recall': best_recall,\n",
    "    'final_recall': final_recall,\n",
    "    'baseline_best_recall': best_baseline\n",
    "}\n",
    "with open(OUT_DIR/'twotower_results.json','w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"Saved Two-Tower results to twotower_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
