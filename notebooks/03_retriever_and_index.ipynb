{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77922aa6-6335-4516-9309-c87d05298c4f",
   "metadata": {},
   "source": [
    "# 03: Two-Tower Retriever\n",
    "\n",
    "This notebook implements and trains a Two-Tower retrieval model:\n",
    "\n",
    "1. **Configuration & Imports**: set hyperparameters and load libraries\n",
    "2. **Data Loading**: read sequences and maps from preprocessed data\n",
    "3. **Model Architecture**: define user and item towers\n",
    "4. **Dataset & DataLoader**: prepare PyTorch datasets and collators\n",
    "5. **Initialize & Compile**: instantiate model, optimizer, scheduler\n",
    "6. **Training Loop**: train with in-batch negatives and early stopping\n",
    "7. **Save Embeddings**: export trained user/item embeddings\n",
    "8. **Evaluation & Comparison**: compute Recall@K and compare to baselines\n",
    "9. **Results Persistence**: save training logs and final metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca517f8-b888-45d5-b624-e2b4d1de5b6e",
   "metadata": {},
   "source": [
    "## 1. Configuration & Imports\n",
    "\n",
    "- Define paths for input/output\n",
    "- Set model, training, and optimization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc6e5c7-8577-4916-a279-cecad5d937b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Global reproducibility\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "try:\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "except Exception:\n",
    "    pass\n",
    "if hasattr(torch.backends, 'cudnn'):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Paths\n",
    "OUT_DIR = Path('../data/processed/jarir/')\n",
    "SEQ_TRAIN = OUT_DIR / 'sequences_train.parquet'\n",
    "SEQ_VAL   = OUT_DIR / 'sequences_val.parquet'\n",
    "ITEM_MAP   = OUT_DIR / 'item_id_map.parquet'\n",
    "CUST_MAP   = OUT_DIR / 'customer_id_map.parquet'\n",
    "BASELINE_RESULTS = OUT_DIR / 'baseline_results.json'\n",
    "\n",
    "# Model & Training Config\n",
    "CFG = {\n",
    "    'd_model':256,\n",
    "    'batch_size':512,\n",
    "    'accum_steps':2,\n",
    "    'epochs':50,\n",
    "    'patience':6,\n",
    "    'lr':5e-4,\n",
    "    'weight_decay':1e-4,\n",
    "    'dropout':0.2,\n",
    "    'eval_topk':10,\n",
    "    'seed':42,\n",
    "    'k_neg':50,\n",
    "    # Retrieval training improvements\n",
    "    'temperature': 0.07,\n",
    "    'use_q_correction': True,\n",
    "    'dev_split_q': 0.90,\n",
    "}\n",
    "# Reproducibility\n",
    "# Already done globally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531b212-b1e7-449d-91fd-c9852b7522ab",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "- Load train/val sequences and id maps\n",
    "- Print dataset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "947daa09-3829-49b5-8781-207ee471fc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train sequences: 1108\n",
      "Val   sequences: 169\n",
      "# items: 1735, # users: 929\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "seq_train = pd.read_parquet(SEQ_TRAIN, engine='fastparquet')\n",
    "seq_val   = pd.read_parquet(SEQ_VAL,   engine='fastparquet')\n",
    "item_map  = pd.read_parquet(ITEM_MAP, engine='fastparquet')\n",
    "cust_map  = pd.read_parquet(CUST_MAP, engine='fastparquet')\n",
    "print(f\"Train sequences: {len(seq_train)}\")\n",
    "print(f\"Val   sequences: {len(seq_val)}\")\n",
    "print(f\"# items: {len(item_map)}, # users: {len(cust_map)}\")\n",
    "\n",
    "# Load baseline results for comparison later\n",
    "with open(BASELINE_RESULTS) as f:\n",
    "    baseline_results = json.load(f)['held_out_interactions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc0ab6e-1c8f-4ca1-a376-ad9f62fcb696",
   "metadata": {},
   "source": [
    "## 3. Two-Tower Model Architecture\n",
    "\n",
    "- Two MLP towers with embedding + LayerNorm + ReLU + Dropout\n",
    "- Normalize final vectors for cosine similarity scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539a9f94-7b2b-43cb-a7f0-d8d8b9c9ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, d_model, dropout):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_model)\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.fc2 = nn.Linear(d_model, d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        h = self.dropout(F.relu(self.ln1(self.fc1(x))))\n",
    "        h = self.dropout(F.relu(self.ln2(self.fc2(h))))\n",
    "        return F.relu(x + h)\n",
    "\n",
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, n_users, n_items, d_model, dropout):\n",
    "        super().__init__()\n",
    "        # Embeddings\n",
    "        self.user_emb = nn.Embedding(n_users, d_model)\n",
    "        self.item_emb = nn.Embedding(n_items, d_model)\n",
    "        # Towers with residual blocks\n",
    "        self.user_block1 = ResidualBlock(d_model, dropout)\n",
    "        self.user_block2 = ResidualBlock(d_model, dropout)\n",
    "        self.item_block1 = ResidualBlock(d_model, dropout)\n",
    "        self.item_block2 = ResidualBlock(d_model, dropout)\n",
    "        self.ln_u = nn.LayerNorm(d_model)\n",
    "        self.ln_i = nn.LayerNorm(d_model)\n",
    "        # init\n",
    "        nn.init.normal_(self.user_emb.weight, 0, 0.1)\n",
    "        nn.init.normal_(self.item_emb.weight, 0, 0.1)\n",
    "    def user_vec(self, uids):\n",
    "        u = self.user_emb(uids)\n",
    "        u = self.user_block1(u)\n",
    "        u = self.user_block2(u)\n",
    "        u = self.ln_u(u)\n",
    "        return F.normalize(u, p=2, dim=1)\n",
    "    def item_vec(self, iids):\n",
    "        v = self.item_emb(iids)\n",
    "        v = self.item_block1(v)\n",
    "        v = self.item_block2(v)\n",
    "        v = self.ln_i(v)\n",
    "        return F.normalize(v, p=2, dim=1)\n",
    "    def forward(self, uids, pos_i, neg_i=None):\n",
    "        u_vec = self.user_vec(uids)\n",
    "        pos_vec = self.item_vec(pos_i)\n",
    "        # InfoNCE-style temperature\n",
    "        scale = 1.0 / max(CFG['temperature'], 1e-6)\n",
    "        pos_scores = (u_vec * pos_vec).sum(1) * scale\n",
    "        if neg_i is None:\n",
    "            return pos_scores\n",
    "        neg_vecs = self.item_vec(neg_i.view(-1)).view(uids.size(0), -1, u_vec.size(-1))\n",
    "        neg_scores = torch.sum(u_vec.unsqueeze(1) * neg_vecs, dim=2) * scale\n",
    "        return pos_scores, neg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab2f72-edf1-4c33-aefa-2ad1ab4d44e1",
   "metadata": {},
   "source": [
    "## 4. Dataset & DataLoader\n",
    "\n",
    "- Custom `Dataset` sampling `k_neg` negatives per example\n",
    "- Collate with padding for variable-length history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac651f6-9941-427d-9ef3-0b956eca6693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 2, Dev batches: 1, Val batches: 1\n"
     ]
    }
   ],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, df, n_items, k_neg):\n",
    "        self.df = df; self.n_items = n_items; self.k_neg = k_neg\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        u = torch.tensor(int(row['user_idx']), dtype=torch.long)\n",
    "        pos = torch.tensor(int(row['pos_item_idx']), dtype=torch.long)\n",
    "        hist = []\n",
    "        if pd.notna(row['history_idx']): hist = [int(x) for x in row['history_idx'].split()]\n",
    "        # sample negatives (avoid false negatives by excluding user's positives if available)\n",
    "        forbid = set(hist + [int(pos)])\n",
    "        avail = list(set(range(self.n_items)) - forbid)\n",
    "        neg = np.random.choice(avail, size=self.k_neg, replace=len(avail)<self.k_neg)\n",
    "        return {'user':u, 'pos':pos, 'neg':torch.tensor(neg, dtype=torch.long), 'hist':torch.tensor(hist, dtype=torch.long)}\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    users = torch.stack([b['user'] for b in batch])\n",
    "    pos   = torch.stack([b['pos'] for b in batch])\n",
    "    neg   = torch.stack([b['neg'] for b in batch])\n",
    "    hists = pad_sequence([b['hist'] for b in batch], batch_first=True, padding_value=-1)\n",
    "    mask  = (hists >= 0)\n",
    "    return {'user':users, 'pos':pos, 'neg':neg, 'hist':hists, 'mask':mask}\n",
    "\n",
    "# Dev split from train to avoid tuning on val during training\n",
    "q = CFG['dev_split_q']\n",
    "cut_ts = seq_train['ts'].quantile(q) if 'ts' in seq_train.columns else None\n",
    "seq_train_tr = seq_train if cut_ts is None else seq_train[seq_train['ts'] < cut_ts]\n",
    "seq_train_dev = pd.DataFrame(columns=seq_train.columns) if cut_ts is None else seq_train[seq_train['ts'] >= cut_ts]\n",
    "\n",
    "train_ds = SequenceDataset(seq_train_tr, len(item_map), CFG['k_neg'])\n",
    "dev_ds   = SequenceDataset(seq_train_dev, len(item_map), CFG['k_neg']) if len(seq_train_dev)>0 else None\n",
    "val_ds   = SequenceDataset(seq_val,   len(item_map), CFG['k_neg'])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=CFG['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
    "dev_loader   = DataLoader(dev_ds,   batch_size=CFG['batch_size'], shuffle=False, collate_fn=collate_fn) if dev_ds is not None else None\n",
    "val_loader   = DataLoader(val_ds,   batch_size=CFG['batch_size'], shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}, Dev batches: {0 if dev_ds is None else len(dev_loader)}, Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed94a3-0a33-4ca1-ad34-a8777ca28dbc",
   "metadata": {},
   "source": [
    "## 5. Initialize Model, Optimizer & Scheduler\n",
    "\n",
    "- Use `AdamW` and `ReduceLROnPlateau` on Recall@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1339bfd4-5556-44e7-bbce-6e0186349bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoTowerModel(len(cust_map), len(item_map), CFG['d_model'], CFG['dropout']).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "# Loss: InfoNCE with temperature and optional q-correction to reduce false negatives impact\n",
    "\n",
    "def info_nce_loss(u_vec, pos_vec, neg_vecs, temperature):\n",
    "    # u_vec: [B, D], pos_vec: [B, D], neg_vecs: [B, K, D]\n",
    "    scale = 1.0 / max(temperature, 1e-6)\n",
    "    pos_logits = (u_vec * pos_vec).sum(1) * scale                     # [B]\n",
    "    neg_logits = (u_vec.unsqueeze(1) * neg_vecs).sum(2) * scale       # [B, K]\n",
    "    logits = torch.cat([pos_logits.unsqueeze(1), neg_logits], dim=1)  # [B, 1+K]\n",
    "    labels = torch.zeros(u_vec.size(0), dtype=torch.long, device=device)\n",
    "    # Optional: q-correction (subtract log-prior approx by item popularity)\n",
    "    if CFG.get('use_q_correction', False):\n",
    "        with torch.no_grad():\n",
    "            # Approx prior as uniform over negatives; leave pos unchanged\n",
    "            q = torch.zeros_like(logits)\n",
    "            q[:, 1:] = -np.log(neg_vecs.size(1))\n",
    "        logits = logits + q\n",
    "    return F.cross_entropy(logits, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea148d51-2856-4001-8e45-9270900fda2e",
   "metadata": {},
   "source": [
    "## 6. Training Loop\n",
    "\n",
    "- Train for up to `epochs`, early stop on validation Recall@K\n",
    "- Track training loss and validation Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bc54df7-2fdf-41f6-a3cd-057a06350a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.9241, Dev Recall@10=0.0000\n",
      "Epoch 2: Loss=0.8371, Dev Recall@10=0.0088\n",
      "Epoch 3: Loss=0.7862, Dev Recall@10=0.0354\n",
      "Epoch 4: Loss=0.7538, Dev Recall@10=0.0708\n",
      "Epoch 5: Loss=0.7094, Dev Recall@10=0.0973\n",
      "Epoch 6: Loss=0.6882, Dev Recall@10=0.0973\n",
      "Epoch 7: Loss=0.6642, Dev Recall@10=0.0973\n",
      "Epoch 8: Loss=0.6359, Dev Recall@10=0.0973\n",
      "Epoch 9: Loss=0.6173, Dev Recall@10=0.0973\n",
      "Epoch 10: Loss=0.5928, Dev Recall@10=0.0973\n",
      "Epoch 11: Loss=0.5926, Dev Recall@10=0.1062\n",
      "Epoch 12: Loss=0.5864, Dev Recall@10=0.1062\n",
      "Epoch 13: Loss=0.5802, Dev Recall@10=0.1062\n",
      "Epoch 14: Loss=0.5712, Dev Recall@10=0.1062\n",
      "Epoch 15: Loss=0.5717, Dev Recall@10=0.1062\n",
      "Epoch 16: Loss=0.5542, Dev Recall@10=0.1150\n",
      "Epoch 17: Loss=0.5529, Dev Recall@10=0.1150\n",
      "Epoch 18: Loss=0.5473, Dev Recall@10=0.1062\n",
      "Epoch 19: Loss=0.5488, Dev Recall@10=0.1062\n",
      "Epoch 20: Loss=0.5517, Dev Recall@10=0.1062\n",
      "Epoch 21: Loss=0.5524, Dev Recall@10=0.1062\n",
      "Epoch 22: Loss=0.5399, Dev Recall@10=0.1062\n",
      "Early stopping.\n",
      "Best Dev Recall@10: 0.1150\n"
     ]
    }
   ],
   "source": [
    "best_recall = 0.0; patience_counter = 0\n",
    "train_losses = []; dev_recalls = []\n",
    "for epoch in range(1, CFG['epochs']+1):\n",
    "    model.train(); total_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader, 1):\n",
    "        u = batch['user'].to(device)\n",
    "        p = batch['pos'].to(device)\n",
    "        n = batch['neg'].to(device)\n",
    "        # Forward for vectors, then InfoNCE\n",
    "        u_vec = model.user_vec(u)\n",
    "        pos_vec = model.item_vec(p)\n",
    "        neg_vecs = model.item_vec(n.view(-1)).view(u.size(0), -1, u_vec.size(-1))\n",
    "        loss = info_nce_loss(u_vec, pos_vec, neg_vecs, CFG['temperature']) / CFG['accum_steps']\n",
    "        loss.backward()\n",
    "        if i % CFG['accum_steps'] == 0:\n",
    "            optimizer.step(); optimizer.zero_grad()\n",
    "        total_loss += loss.item() * CFG['accum_steps']\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    # Dev evaluation (held-out slice from train) to avoid using val during training\n",
    "    model.eval(); hits = []\n",
    "    loader = dev_loader if dev_loader is not None else val_loader\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            u = batch['user'].to(device)\n",
    "            p = batch['pos'].to(device)\n",
    "            u_vec = model.user_vec(u)\n",
    "            all_items = torch.arange(len(item_map), device=device)\n",
    "            i_vecs = model.item_vec(all_items)\n",
    "            scores = u_vec @ i_vecs.T\n",
    "            topk = scores.topk(CFG['eval_topk'], dim=1).indices\n",
    "            hits.append((topk == p.unsqueeze(1)).any(1).float().mean().item())\n",
    "    dev_recall = np.mean(hits); dev_recalls.append(dev_recall)\n",
    "    scheduler.step(dev_recall)\n",
    "    print(f\"Epoch {epoch}: Loss={avg_loss:.4f}, Dev Recall@{CFG['eval_topk']}={dev_recall:.4f}\")\n",
    "    if dev_recall > best_recall:\n",
    "        best_recall = dev_recall; patience_counter = 0\n",
    "        torch.save(model.state_dict(), OUT_DIR/'best_twotower_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= CFG['patience']:\n",
    "            print(\"Early stopping.\"); break\n",
    "print(f\"Best Dev Recall@{CFG['eval_topk']}: {best_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290ad58-f1c6-4baa-bfc7-30d0a1edad42",
   "metadata": {},
   "source": [
    "## 7. Save Embeddings\n",
    "\n",
    "- Generate and save all user and item embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e6e5d58-175f-4c37-a886-aa938295de92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings shapes: (929, 256), (1735, 256)\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(OUT_DIR/'best_twotower_model.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    users = torch.arange(len(cust_map), device=device)\n",
    "    items = torch.arange(len(item_map), device=device)\n",
    "    u_emb = model.user_vec(users).cpu().numpy()\n",
    "    i_emb = model.item_vec(items).cpu().numpy()\n",
    "    np.save(OUT_DIR/'user_embeddings.npy', u_emb)\n",
    "    np.save(OUT_DIR/'item_embeddings.npy', i_emb)\n",
    "print(f\"Saved embeddings shapes: {u_emb.shape}, {i_emb.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6200103b-e3fa-4546-b4dd-87f62168b99e",
   "metadata": {},
   "source": [
    "## 8. Evaluation & Comparison\n",
    "\n",
    "- Reload best model and compute final Recall@K\n",
    "- Compare to baselines loaded earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2537a9e5-086c-4bd6-9cf8-65c651402c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Tower Recall@10: 0.1183\n",
      "Best baseline    : 0.1124\n"
     ]
    }
   ],
   "source": [
    "# Final eval on true validation set\n",
    "model.eval(); hits = []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        u=batch['user'].to(device); p=batch['pos'].to(device)\n",
    "        u_vec=model.user_vec(u)\n",
    "        all_items = torch.arange(len(item_map), device=device)\n",
    "        i_vecs = model.item_vec(all_items)\n",
    "        scores=u_vec @ i_vecs.T\n",
    "        topk=scores.topk(CFG['eval_topk'],dim=1).indices\n",
    "        hits.append((topk==p.unsqueeze(1)).any(1).float().mean().item())\n",
    "final_recall = np.mean(hits)\n",
    "# Read baseline best recall at matching K, supporting both old and new schema\n",
    "final_k = CFG['eval_topk']\n",
    "try:\n",
    "    # New schema from notebook 02: model -> {'K=10': {'Recall', 'NDCG', 'MRR'}}\n",
    "    k_key = f'K={final_k}'\n",
    "    best_baseline = max(\n",
    "        baseline_results.items(),\n",
    "        key=lambda x: x[1][k_key]['Recall'] if (k_key in x[1]) else -1.0\n",
    "    )[1][k_key]['Recall']\n",
    "except Exception:\n",
    "    # Backward compatibility: old schema model -> {'Recall@10': value}\n",
    "    recall_key = f'Recall@{final_k}'\n",
    "    best_baseline = max(\n",
    "        baseline_results.items(),\n",
    "        key=lambda x: x[1].get(recall_key, -1.0)\n",
    "    )[1].get(recall_key, float('nan'))\n",
    "\n",
    "print(f\"Two-Tower Recall@{CFG['eval_topk']}: {final_recall:.4f}\")\n",
    "print(f\"Best baseline    : {best_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b3320-3837-4eaf-bd2a-2729e8aa5b49",
   "metadata": {},
   "source": [
    "## 9. Save Results\n",
    "\n",
    "- Persist model config, training curves, and comparison metrics to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20847ef6-8105-4484-acd0-84bfa12dcfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Two-Tower results to twotower_results.json\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    'model_config': CFG,\n",
    "    'training': {'train_losses': train_losses, 'dev_recalls': dev_recalls},\n",
    "    'best_dev_recall': best_recall,\n",
    "    'final_val_recall': final_recall,\n",
    "    'baseline_best_recall': best_baseline\n",
    "}\n",
    "with open(OUT_DIR/'twotower_results.json','w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"Saved Two-Tower results to twotower_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc490a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
