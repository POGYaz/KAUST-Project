{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ab5614-6240-456f-9496-af8736d95636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c8b660-1090-4984-9f93-82489c0eba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Jarir dataset...\n",
      "Original columns: ['Showroom', 'GL Class', 'Classification Description', 'ItemDescription', 'ShortItemNo', 'Model', 'Vendor Prefix', 'Brand', 'ItemNumber', 'Date', 'SalesChannel', 'CustomerId', 'Customer_VAT_Status', 'UNQTRN', 'Sales Quantity 2024', 'No of Trans 2024', 'Sales Amount 2024']\n",
      "Original data shape: (3001, 17)\n",
      "Columns after renaming: ['country', 'category', 'Classification Description', 'description', 'short_item_no', 'model', 'vendor', 'brand', 'stock_code', 'invoice_date', 'sales_channel', 'customer_id', 'vat_status', 'unique_transaction', 'quantity', 'num_transactions', 'line_amount']\n",
      "Fixing date parsing for Jarir...\n",
      "Original date sample: 0    Jan-1\n",
      "1    Jan-1\n",
      "2    Jan-1\n",
      "3    Jan-1\n",
      "4    Jan-2\n",
      "Name: invoice_date, dtype: object\n",
      "Original date dtype: object\n",
      "Parsed dates sample: 0   2024-01-01\n",
      "1   2024-01-01\n",
      "2   2024-01-01\n",
      "3   2024-01-01\n",
      "4   2024-01-02\n",
      "Name: invoice_date, dtype: datetime64[ns]\n",
      "Valid dates: 3001\n",
      "Loaded rows: 3001\n",
      "✅ Saved cleaned tables to ../data/processed/jarir\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sequences saved: 1108 train | 169 val | 160 test\n",
      "Time cuts: 2024-01-01 00:00:00 → 2024-10-14 00:00:00 → 2024-11-21 00:00:00 → 2024-12-31 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>user_idx</th>\n",
       "      <th>ts</th>\n",
       "      <th>history_idx</th>\n",
       "      <th>pos_item_idx</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10018322</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>66 76</td>\n",
       "      <td>1120</td>\n",
       "      <td>0103-PLAZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10018322</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-03-24</td>\n",
       "      <td>66 76 1120</td>\n",
       "      <td>1041</td>\n",
       "      <td>0103-PLAZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10018322</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>66 76 1120 1041</td>\n",
       "      <td>317</td>\n",
       "      <td>0103-PLAZA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  user_idx         ts      history_idx  pos_item_idx     country\n",
       "0     10018322         1 2024-03-07            66 76          1120  0103-PLAZA\n",
       "1     10018322         1 2024-03-24       66 76 1120          1041  0103-PLAZA\n",
       "2     10018322         1 2024-04-30  66 76 1120 1041           317  0103-PLAZA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id_map.parquet -> exists=True size=28975\n",
      "customer_id_map.parquet -> exists=True size=12834\n",
      "sequences_train.parquet -> exists=True size=26594\n",
      "sequences_val.parquet -> exists=True size=8181\n",
      "sequences_test.parquet -> exists=True size=8182\n",
      "(1108, 6)\n",
      "   customer_id  user_idx         ts      history_idx  pos_item_idx     country\n",
      "0     10018322         1 2024-03-07            66 76          1120  0103-PLAZA\n",
      "1     10018322         1 2024-03-24       66 76 1120          1041  0103-PLAZA\n",
      "2     10018322         1 2024-04-30  66 76 1120 1041           317  0103-PLAZA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1735"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Config\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata, re, json\n",
    "from datetime import datetime\n",
    "\n",
    "DATA_PATH = Path('../data/raw/jarir.xlsx')   # Jarir dataset\n",
    "OUT_DIR = Path('../data/processed/jarir/')  # Jarir output directory\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cleaning toggles / thresholds\n",
    "KEEP_ONLY_POSITIVE_QTY = True\n",
    "KEEP_ONLY_POSITIVE_PRICE = True\n",
    "DROP_RETURNS_BY_INVOICE_PREFIX = True   # transactions starting with 'C'\n",
    "DROP_DUPLICATE_ROWS = True\n",
    "\n",
    "# Non-product removal rules (description patterns; case-insensitive)\n",
    "NON_PRODUCT_PATTERNS = [\n",
    "    r'POSTAGE', r'SHIPPING', r'CARRIAGE', r'DELIVERY',\n",
    "    r'BANK CHARGES', r'AMAZON', r'DOTCOM', r'PACKING', r'ADJUST', r'DISCOUNT',\n",
    "    r'SAMPLE', r'SAMPLES', r'CHECK', r'TEST', r'MANUAL', r'FEE', r'CHARGE'\n",
    "]\n",
    "\n",
    "# Outlier handling (IQR on log values)\n",
    "HANDLE_OUTLIERS = True\n",
    "WINSORIZE_INSTEAD_OF_DROP = False   # if False, drop; if True, cap to bounds\n",
    "LOG_EPS = 1e-6\n",
    "IQR_MULT = 3.0     # 3*IQR is conservative on log scale\n",
    "\n",
    "# Coverage filters (optional; applied after core cleaning)\n",
    "MIN_EVENTS_PER_USER = 1       # set 1 to keep all users\n",
    "MIN_PURCHASES_PER_ITEM = 1    # set 1 to keep all items\n",
    "\n",
    "# Randomness\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# --- Load Excel file\n",
    "print(\"Loading Jarir dataset...\")\n",
    "raw = pd.read_excel(DATA_PATH, engine='openpyxl')\n",
    "\n",
    "print(\"Original columns:\", raw.columns.tolist())\n",
    "print(\"Original data shape:\", raw.shape)\n",
    "\n",
    "# --- Date parsing function for Jarir format ---\n",
    "def parse_jarir_dates(date_series):\n",
    "    \"\"\"\n",
    "    Parse Jarir dates like 'Jan-1', 'Jan-2', etc.\n",
    "    Returns datetime series with 2024 as the year.\n",
    "    \"\"\"\n",
    "    def parse_single_date(date_str):\n",
    "        if pd.isna(date_str):\n",
    "            return pd.NaT\n",
    "        \n",
    "        try:\n",
    "            # Handle formats like 'Jan-1', 'Jan-2', etc.\n",
    "            if isinstance(date_str, str) and '-' in date_str:\n",
    "                month_day = date_str.split('-')\n",
    "                if len(month_day) == 2:\n",
    "                    month_str = month_day[0].strip()\n",
    "                    day_str = month_day[1].strip()\n",
    "                    \n",
    "                    # Month mapping\n",
    "                    month_map = {\n",
    "                        'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4,\n",
    "                        'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8,\n",
    "                        'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
    "                    }\n",
    "                    \n",
    "                    if month_str in month_map and day_str.isdigit():\n",
    "                        month = month_map[month_str]\n",
    "                        day = int(day_str)\n",
    "                        # Use 2024 as the year\n",
    "                        return pd.Timestamp(2024, month, day)\n",
    "            return pd.NaT\n",
    "        except:\n",
    "            return pd.NaT\n",
    "    \n",
    "    return pd.to_datetime(date_series.apply(parse_single_date), errors='coerce')\n",
    "\n",
    "# --- Standardize column names for Jarir data ---\n",
    "# Map actual Jarir columns to standard names\n",
    "rename_map = {\n",
    "    'ItemNumber': 'stock_code',\n",
    "    'ItemDescription': 'description',\n",
    "    'CustomerId': 'customer_id',\n",
    "    'Sales Quantity 2024': 'quantity',\n",
    "    'Sales Amount 2024': 'line_amount',\n",
    "    'Date': 'invoice_date',\n",
    "    'Showroom': 'country',  # Use showroom as country equivalent\n",
    "    'Brand': 'brand',\n",
    "    'GL Class': 'category',\n",
    "    'Vendor Prefix': 'vendor',\n",
    "    'Model': 'model',\n",
    "    'ShortItemNo': 'short_item_no',\n",
    "    'SalesChannel': 'sales_channel',\n",
    "    'Customer_VAT_Status': 'vat_status',\n",
    "    'UNQTRN': 'unique_transaction',\n",
    "    'No of Trans 2024': 'num_transactions'\n",
    "}\n",
    "\n",
    "# Apply renaming for columns that exist\n",
    "for old_col, new_col in rename_map.items():\n",
    "    if old_col in raw.columns:\n",
    "        raw.rename(columns={old_col: new_col}, inplace=True)\n",
    "\n",
    "print(\"Columns after renaming:\", raw.columns.tolist())\n",
    "\n",
    "# --- Fix date parsing for Jarir ---\n",
    "print(\"Fixing date parsing for Jarir...\")\n",
    "print(\"Original date sample:\", raw['invoice_date'].head())\n",
    "print(\"Original date dtype:\", raw['invoice_date'].dtype)\n",
    "\n",
    "# Use our custom date parsing function\n",
    "raw['invoice_date'] = parse_jarir_dates(raw['invoice_date'])\n",
    "\n",
    "print(\"Parsed dates sample:\", raw['invoice_date'].head())\n",
    "print(\"Valid dates:\", raw['invoice_date'].notna().sum())\n",
    "\n",
    "# If all dates are invalid, create synthetic dates\n",
    "if raw['invoice_date'].isna().all():\n",
    "    print(\"\\n❌ All dates are invalid. Creating synthetic dates...\")\n",
    "    raw['invoice_date'] = pd.date_range(start='2024-01-01', periods=len(raw), freq='D')\n",
    "    print(\"Created synthetic dates\")\n",
    "\n",
    "# --- Add price column (line_amount / quantity) ---\n",
    "raw['price'] = raw['line_amount'] / raw['quantity']\n",
    "\n",
    "print('Loaded rows:', len(raw))\n",
    "raw.head(3)\n",
    "\n",
    "## Step 1 — Basic validity filters\n",
    "\n",
    "quality = {}\n",
    "df = raw.copy()\n",
    "\n",
    "# Missing critical fields\n",
    "before = len(df)\n",
    "df = df[df['invoice_date'].notna() & df['stock_code'].notna() & df['description'].notna() & df['country'].notna() & df['customer_id'].notna()]\n",
    "quality['drop_missing_core'] = before - len(df)\n",
    "\n",
    "# Returns by invoice prefix 'C' (if applicable)\n",
    "if DROP_RETURNS_BY_INVOICE_PREFIX and 'unique_transaction' in df.columns:\n",
    "    before = len(df)\n",
    "    mask = df['unique_transaction'].astype(str).str.startswith('C', na=False)\n",
    "    df = df[~mask]\n",
    "    quality['drop_returns_invoice_prefix'] = before - len(df)\n",
    "\n",
    "# Positive quantity/price\n",
    "if KEEP_ONLY_POSITIVE_QTY:\n",
    "    before = len(df)\n",
    "    df = df[df['quantity'] > 0]\n",
    "    quality['drop_nonpositive_qty'] = before - len(df)\n",
    "\n",
    "if KEEP_ONLY_POSITIVE_PRICE:\n",
    "    before = len(df)\n",
    "    df = df[df['price'] > 0]\n",
    "    quality['drop_nonpositive_price'] = before - len(df)\n",
    "\n",
    "# Drop duplicate rows (exact duplicates)\n",
    "if DROP_DUPLICATE_ROWS:\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates()\n",
    "    quality['drop_exact_duplicates'] = before - len(df)\n",
    "\n",
    "len(df), quality\n",
    "\n",
    "## Step 2 — Text normalization & non‑product removal\n",
    "\n",
    "# Text normalization helpers\n",
    "def normalize_text(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        s = '' if pd.isna(s) else str(s)\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'\\s+', ' ', s)               # collapse whitespace\n",
    "    s = unicodedata.normalize('NFKC', s)      # unicode normalization\n",
    "    return s.upper()                           # uppercase for matching\n",
    "\n",
    "df['description'] = df['description'].astype(str).map(normalize_text)\n",
    "df['stock_code'] = df['stock_code'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Remove non-product lines by description patterns\n",
    "pattern = re.compile('|'.join(NON_PRODUCT_PATTERNS), flags=re.IGNORECASE)\n",
    "before = len(df)\n",
    "df = df[~df['description'].str.contains(pattern)]\n",
    "quality['drop_non_product_patterns'] = before - len(df)\n",
    "\n",
    "len(df), df['description'].head(5).tolist()[:3]\n",
    "\n",
    "## Step 3 — De‑duplicate & aggregate duplicate transaction lines\n",
    "\n",
    "# Some transactions may repeat the same stock_code line; aggregate quantities & compute line_amount\n",
    "df['line_amount'] = df['quantity'] * df['price']\n",
    "\n",
    "# Aggregate per (customer_id, stock_code, invoice_date) for Jarir\n",
    "agg_cols = {\n",
    "    'quantity':'sum',\n",
    "    'price':'mean',          # average price across repeats\n",
    "    'line_amount':'sum',\n",
    "    'description':'first',   # keep first normalized description\n",
    "    'country':'first',\n",
    "    'brand':'first',\n",
    "    'category':'first',\n",
    "    'vendor':'first',\n",
    "    'invoice_date':'first',\n",
    "}\n",
    "before = len(df)\n",
    "df = df.groupby(['customer_id','stock_code','invoice_date'], as_index=False).agg(agg_cols)\n",
    "quality['aggregated_duplicate_lines'] = before - len(df)\n",
    "\n",
    "len(df), df.head(3)\n",
    "\n",
    "## Step 4 — Outlier detection & handling (IQR on log scale)\n",
    "\n",
    "def iqr_bounds_log(series, mult=IQR_MULT, eps=LOG_EPS):\n",
    "    s = np.log(series.clip(lower=eps))\n",
    "    # Handle NaN values properly\n",
    "    s_clean = s.dropna()\n",
    "    if len(s_clean) == 0:\n",
    "        return 0, 0\n",
    "    q1, q3 = np.percentile(s_clean, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lo, hi = q1 - mult*iqr, q3 + mult*iqr\n",
    "    return np.exp(lo), np.exp(hi)\n",
    "\n",
    "if HANDLE_OUTLIERS:\n",
    "    # Bounds for unit price, quantity, and line_amount\n",
    "    price_lo, price_hi = iqr_bounds_log(df['price'])\n",
    "    qty_lo, qty_hi = iqr_bounds_log(df['quantity'])\n",
    "    amt_lo, amt_hi = iqr_bounds_log(df['line_amount'])\n",
    "\n",
    "    # Apply handling\n",
    "    def handle(series, lo, hi, name):\n",
    "        before = len(series)\n",
    "        if WINSORIZE_INSTEAD_OF_DROP:\n",
    "            clipped = series.clip(lower=lo, upper=hi)\n",
    "            removed = 0\n",
    "            return clipped, removed\n",
    "        else:\n",
    "            mask = (series >= lo) & (series <= hi)\n",
    "            removed = int((~mask).sum())\n",
    "            return series[mask], removed\n",
    "\n",
    "    # Because handling may change row counts, operate via mask\n",
    "    mask_price = (df['price'] >= price_lo) & (df['price'] <= price_hi)\n",
    "    mask_qty = (df['quantity'] >= qty_lo) & (df['quantity'] <= qty_hi)\n",
    "    mask_amt = (df['line_amount'] >= amt_lo) & (df['line_amount'] <= amt_hi)\n",
    "    combined_mask = mask_price & mask_qty & mask_amt\n",
    "\n",
    "    before = len(df)\n",
    "    df = df[combined_mask].copy()\n",
    "    quality['drop_outliers'] = before - len(df)\n",
    "\n",
    "# Recompute line_amount after any clipping (if winsorized, we would recompute here)\n",
    "df['line_amount'] = df['quantity'] * df['price']\n",
    "\n",
    "len(df)\n",
    "\n",
    "## Step 5 — Optional coverage filters (rare users/items)\n",
    "\n",
    "# These are optional; useful for sequential models to ensure enough history.\n",
    "# Set thresholds to 1 above if you want to skip dropping rare entities.\n",
    "\n",
    "# Filter items with too few purchases\n",
    "if MIN_PURCHASES_PER_ITEM > 1:\n",
    "    item_counts = df.groupby('stock_code').size()\n",
    "    keep_items = set(item_counts[item_counts >= MIN_PURCHASES_PER_ITEM].index)\n",
    "    before = len(df)\n",
    "    df = df[df['stock_code'].isin(keep_items)]\n",
    "    quality['drop_rare_items'] = before - len(df)\n",
    "\n",
    "# Filter users with too few events\n",
    "if MIN_EVENTS_PER_USER > 1:\n",
    "    user_counts = df.groupby('customer_id').size()\n",
    "    keep_users = set(user_counts[user_counts >= MIN_EVENTS_PER_USER].index)\n",
    "    before = len(df)\n",
    "    df = df[df['customer_id'].isin(keep_users)]\n",
    "    quality['drop_rare_users'] = before - len(df)\n",
    "\n",
    "len(df)\n",
    "\n",
    "## Step 6 — Final tidy tables & save\n",
    "\n",
    "interactions = (\n",
    "    df[[\n",
    "        'customer_id','invoice_date',\n",
    "        'stock_code','description','quantity',\n",
    "        'price','line_amount','country','brand','category','vendor'\n",
    "    ]].copy()\n",
    "    .sort_values(['customer_id','invoice_date'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Normalize dtypes explicitly (avoid pandas/pyarrow extension dtypes)\n",
    "interactions['stock_code']   = interactions['stock_code'].astype(str)\n",
    "interactions['description']  = interactions['description'].astype(str)\n",
    "interactions['country']      = interactions['country'].astype(str)\n",
    "interactions['brand']        = interactions['brand'].astype(str)\n",
    "interactions['category']     = interactions['category'].astype(str)\n",
    "interactions['vendor']       = interactions['vendor'].astype(str)\n",
    "\n",
    "interactions['invoice_date'] = pd.to_datetime(interactions['invoice_date'], errors='coerce').dt.tz_localize(None)\n",
    "interactions['customer_id']  = pd.to_numeric(interactions['customer_id'], errors='coerce').astype('Int64').astype('int64')\n",
    "interactions['quantity']     = pd.to_numeric(interactions['quantity'], errors='coerce').astype('float64')\n",
    "interactions['price']        = pd.to_numeric(interactions['price'], errors='coerce').astype('float64')\n",
    "interactions['line_amount']  = pd.to_numeric(interactions['line_amount'], errors='coerce').astype('float64')\n",
    "\n",
    "# Drop any rows that became NA in critical fields after coercion\n",
    "interactions = interactions.dropna(subset=['invoice_date','customer_id','stock_code'])\n",
    "\n",
    "# Defensive: convert any stray Period/Interval columns if they slipped in\n",
    "for col in interactions.columns:\n",
    "    dt = interactions[col].dtype\n",
    "    if str(dt).startswith('period'):   # PeriodDtype -> timestamp\n",
    "        interactions[col] = interactions[col].astype('datetime64[ns]')\n",
    "    if str(dt).startswith('interval'): # IntervalDtype -> string\n",
    "        interactions[col] = interactions[col].astype(str)\n",
    "\n",
    "# --- Item catalog ------------------------------------------------------------\n",
    "item_catalog = (\n",
    "    interactions.groupby('stock_code', as_index=False)\n",
    "    .agg(\n",
    "        description=('description', lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]),\n",
    "        price_median=('price', 'median'),\n",
    "        price_mean=('price', 'mean'),\n",
    "        pop=('stock_code', 'size'),\n",
    "        brand=('brand', lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]),\n",
    "        category=('category', lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]),\n",
    "        vendor=('vendor', lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0])\n",
    "    )\n",
    "    .sort_values('pop', ascending=False)\n",
    ")\n",
    "\n",
    "# --- Customer table ----------------------------------------------------------\n",
    "customer_table = (\n",
    "    interactions.groupby('customer_id', as_index=False)\n",
    "    .agg(\n",
    "        first_date=('invoice_date','min'),\n",
    "        last_date =('invoice_date','max'),\n",
    "        n_events  =('invoice_date','nunique'),\n",
    "        n_lines   =('stock_code','size'),\n",
    "        country_mode=('country', lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]),\n",
    "        total_spent=('line_amount','sum')\n",
    "    )\n",
    ")\n",
    "\n",
    "# --- Write to Parquet (no registry hacking) ---------------------------------\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "OUT_DIR = Path(OUT_DIR) if 'OUT_DIR' in globals() else Path('./out')\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def write_parquet_safe(df, path):\n",
    "    # Try pyarrow first\n",
    "    try:\n",
    "        df.to_parquet(path, index=False, engine='pyarrow')\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] pyarrow failed on {path.name}: {e}\\nFalling back to fastparquet...\")\n",
    "        # Fallback: fastparquet (no Arrow extension registry involved)\n",
    "        import fastparquet  # ensure installed: pip install fastparquet\n",
    "        df.to_parquet(path, index=False, engine='fastparquet')\n",
    "\n",
    "write_parquet_safe(interactions,  OUT_DIR / 'interactions_clean.parquet')\n",
    "write_parquet_safe(item_catalog,  OUT_DIR / 'items_clean.parquet')\n",
    "write_parquet_safe(customer_table, OUT_DIR / 'customers_clean.parquet')\n",
    "\n",
    "# --- Quality report ----------------------------------------------------------\n",
    "if 'quality' not in globals():\n",
    "    quality = {}\n",
    "rows_initial = int(len(raw)) if 'raw' in globals() else None\n",
    "\n",
    "report = {\n",
    "    'counts': {'rows_initial': rows_initial, 'rows_final': int(len(interactions))},\n",
    "    'quality': quality\n",
    "}\n",
    "with open(OUT_DIR / 'quality_report.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print('✅ Saved cleaned tables to', OUT_DIR)\n",
    "report\n",
    "\n",
    "## Optional: Quick visual checks\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "interactions['price'].plot(kind='hist', bins=50, title='Unit Price (clean)')\n",
    "plt.xlabel('price'); plt.ylabel('count'); plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "interactions['quantity'].plot(kind='hist', bins=50, title='Quantity (clean)')\n",
    "plt.xlabel('quantity'); plt.ylabel('count'); plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "(interactions['line_amount']).plot(kind='hist', bins=50, title='Line Amount (clean)')\n",
    "plt.xlabel('line_amount'); plt.ylabel('count'); plt.show()\n",
    "\n",
    "## Step 7 — Build user sequences & time-based split (→ train/val/test)\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Inputs from previous steps (or reload if running standalone)\n",
    "OUT_DIR = Path(OUT_DIR) if 'OUT_DIR' in globals() else Path('./out')\n",
    "interactions_path = OUT_DIR / 'interactions_clean.parquet'\n",
    "if 'interactions' not in globals():\n",
    "    interactions = pd.read_parquet(interactions_path)\n",
    "\n",
    "# --- Config ---\n",
    "HIST_MAX      = 15     # cap on history length (reduced for Jarir)\n",
    "MIN_HISTORY   = 2      # require at least this many past items to form a sample\n",
    "SPLIT_QS      = (0.80, 0.90)  # 80%/10%/10% time split by global timestamps\n",
    "SAVE_NEGATIVES = False # set True to also save random negatives for quick tests\n",
    "N_NEG_TRAIN   = 50\n",
    "N_NEG_VALTEST = 100\n",
    "\n",
    "# --- Build stable ID maps (will be reused later) ---\n",
    "items = interactions['stock_code'].astype(str).unique()\n",
    "item_id_map = pd.DataFrame({'stock_code': items}).sort_values('stock_code').reset_index(drop=True)\n",
    "item_id_map['item_idx'] = np.arange(len(item_id_map), dtype=np.int64)\n",
    "\n",
    "customers = interactions['customer_id'].astype('int64').unique()\n",
    "customer_id_map = pd.DataFrame({'customer_id': customers}).sort_values('customer_id').reset_index(drop=True)\n",
    "customer_id_map['user_idx'] = np.arange(len(customer_id_map), dtype=np.int64)\n",
    "\n",
    "# Join indices into interactions (no exotic dtypes)\n",
    "interactions_idx = (\n",
    "    interactions\n",
    "    .merge(item_id_map, on='stock_code', how='left')\n",
    "    .merge(customer_id_map, on='customer_id', how='left')\n",
    "    .sort_values(['customer_id','invoice_date'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# --- Compute global time cutoffs ---\n",
    "t1 = interactions_idx['invoice_date'].quantile(SPLIT_QS[0])\n",
    "t2 = interactions_idx['invoice_date'].quantile(SPLIT_QS[1])\n",
    "\n",
    "def build_sequences(df_user_sorted, t_start, t_end, hist_max=HIST_MAX, min_hist=MIN_HISTORY):\n",
    "    \"\"\"Create (history -> next item) samples whose TARGET time is within [t_start, t_end).\n",
    "       History can include events before t_start to avoid cold history.\"\"\"\n",
    "    rows = []\n",
    "    item_pool = item_id_map['item_idx'].to_numpy()\n",
    "    for uid, g in df_user_sorted.groupby('customer_id', sort=False):\n",
    "        items_idx = g['item_idx'].to_numpy()\n",
    "        times     = g['invoice_date'].to_numpy()\n",
    "        country   = g['country'].iloc[-1]  # last known country\n",
    "        for i in range(1, len(items_idx)):\n",
    "            ts = times[i]\n",
    "            if not (t_start <= ts < t_end):\n",
    "                continue\n",
    "            hist = items_idx[max(0, i - hist_max):i]\n",
    "            if len(hist) < min_hist:\n",
    "                continue\n",
    "            pos  = items_idx[i]\n",
    "            # store as plain strings to keep Parquet simple/robust\n",
    "            rows.append((\n",
    "                uid,\n",
    "                int(df_user_sorted['user_idx'].iloc[i]),\n",
    "                ts,\n",
    "                ' '.join(map(str, hist.tolist())),\n",
    "                int(pos),\n",
    "                str(country)\n",
    "            ))\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=['customer_id','user_idx','ts','history_idx','pos_item_idx','country'])\n",
    "    out = pd.DataFrame(rows, columns=['customer_id','user_idx','ts','history_idx','pos_item_idx','country'])\n",
    "    return out\n",
    "\n",
    "# Split windows (inclusive start, exclusive end)\n",
    "t_min = interactions_idx['invoice_date'].min()\n",
    "t_max = interactions_idx['invoice_date'].max()\n",
    "\n",
    "seq_train = build_sequences(interactions_idx, t_min, t1)\n",
    "seq_val   = build_sequences(interactions_idx, t1,   t2)\n",
    "seq_test  = build_sequences(interactions_idx, t2,   t_max + pd.Timedelta(seconds=1))\n",
    "\n",
    "# --- (Optional) simple random negatives for quick testing ---\n",
    "rng = np.random.default_rng(42)\n",
    "def add_random_negs(df_seq, n_neg):\n",
    "    if df_seq.empty:\n",
    "        df_seq['neg_idx'] = ''\n",
    "        return df_seq\n",
    "    item_pool = item_id_map['item_idx'].to_numpy()\n",
    "    negs = []\n",
    "    for h, pos in zip(df_seq['history_idx'].values, df_seq['pos_item_idx'].values):\n",
    "        hist_set = set(map(int, h.split())) if h else set()\n",
    "        forbid   = hist_set | {int(pos)}\n",
    "        # sample without replacement until we have n_neg or exhaust\n",
    "        choices = item_pool[~np.isin(item_pool, list(forbid))]\n",
    "        if len(choices) == 0:\n",
    "            negs.append('')\n",
    "            continue\n",
    "        take = choices[rng.choice(len(choices), size=min(n_neg, len(choices)), replace=False)]\n",
    "        negs.append(' '.join(map(str, take.tolist())))\n",
    "    df_seq = df_seq.copy()\n",
    "    df_seq['neg_idx'] = negs\n",
    "    return df_seq\n",
    "\n",
    "if SAVE_NEGATIVES:\n",
    "    seq_train = add_random_negs(seq_train, N_NEG_TRAIN)\n",
    "    seq_val   = add_random_negs(seq_val,   N_NEG_VALTEST)\n",
    "    seq_test  = add_random_negs(seq_test,  N_NEG_VALTEST)\n",
    "\n",
    "# --- Save artifacts (plain types; Parquet-friendly) ---\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def write_parquet_safe(df, path):\n",
    "    try:\n",
    "        df.to_parquet(path, index=False, engine='pyarrow')\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] pyarrow failed on {Path(path).name}: {e}\\nFalling back to fastparquet...\")\n",
    "        import fastparquet\n",
    "        df.to_parquet(path, index=False, engine='fastparquet')\n",
    "\n",
    "write_parquet_safe(item_id_map,     OUT_DIR / 'item_id_map.parquet')\n",
    "write_parquet_safe(customer_id_map, OUT_DIR / 'customer_id_map.parquet')\n",
    "write_parquet_safe(seq_train,       OUT_DIR / 'sequences_train.parquet')\n",
    "write_parquet_safe(seq_val,         OUT_DIR / 'sequences_val.parquet')\n",
    "write_parquet_safe(seq_test,        OUT_DIR / 'sequences_test.parquet')\n",
    "\n",
    "print(\"✅ Sequences saved:\",\n",
    "      len(seq_train), \"train |\",\n",
    "      len(seq_val),   \"val |\",\n",
    "      len(seq_test),  \"test\")\n",
    "print(\"Time cuts:\", t_min, \"→\", t1, \"→\", t2, \"→\", t_max)\n",
    "display(seq_train.head(3))\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "OUT_DIR = Path(OUT_DIR)  # if OUT_DIR is a string\n",
    "files = [\n",
    "    'item_id_map.parquet',\n",
    "    'customer_id_map.parquet',\n",
    "    'sequences_train.parquet',\n",
    "    'sequences_val.parquet',\n",
    "    'sequences_test.parquet',\n",
    "]\n",
    "for f in files:\n",
    "    p = OUT_DIR / f\n",
    "    print(f\"{f} -> exists={p.exists()} size={p.stat().st_size if p.exists() else 'NA'}\")\n",
    "\n",
    "# Read a small sample using fastparquet to avoid pyarrow registry issues\n",
    "df_train = pd.read_parquet(OUT_DIR/'sequences_train.parquet', engine='fastparquet')\n",
    "print(df_train.shape)\n",
    "print(df_train.head(3))\n",
    "\n",
    "df[\"stock_code\"].nunique()  # Check unique stock codes in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b23cb6f-f5a4-4dcc-b116-67dfdda4c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA EMB AND BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b50418bc-903b-4d2e-b1fc-2a49d26404ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Jarir interaction data...\n",
      "Sequences: Train=1108, Val=169, Test=160\n",
      "Items: 1735, Customers: 929\n",
      "Customers: 929\n",
      "\n",
      "Sample interactions:\n",
      "   customer_id invoice_date      stock_code  \\\n",
      "0        11949   2024-12-09       RQ-CHB002   \n",
      "1        11949   2024-12-09   ZQ-F27318BGLD   \n",
      "2        24811   2024-09-12      NE-0230059   \n",
      "3        24811   2024-10-08  RQ-A42DR05VWHT   \n",
      "4        24811   2024-11-18       RQ-193024   \n",
      "\n",
      "                                    description  quantity    price  \\\n",
      "0         RQ-CHB002 CERTIFICATE HOLDER PVC BLUE      10.0   15.304   \n",
      "1          ZQ-F27318BGLD CERTIFICATE FRAME GOLD       5.0   27.132   \n",
      "2      NE-0230059 STAPLER HEAVY DUTY B56 200 SH       1.0  402.780   \n",
      "3  RQ-A42DR05VWHT BINDER 2D 0.5\"RING/1.25\"SPINE       8.0   10.435   \n",
      "4           RQ-193024 CRAYON WAX 24 COL REGULAR      15.0    4.174   \n",
      "\n",
      "   line_amount     country        brand               category  \\\n",
      "0       153.04  0103-PLAZA         Roco  IN02  OFFICE SUPPLIES   \n",
      "1       135.66  0103-PLAZA  Non Branded  IN02  OFFICE SUPPLIES   \n",
      "2       402.78  0103-PLAZA        Novus  IN02  OFFICE SUPPLIES   \n",
      "3        83.48  0103-PLAZA         Roco  IN02  OFFICE SUPPLIES   \n",
      "4        62.61  0103-PLAZA         Roco  IN01  SCHOOL SUPPLIES   \n",
      "\n",
      "                                      vendor  user_idx  item_idx  \n",
      "0         RQ- ROCO BRAND JARIR MARKETING CO.         0      1430  \n",
      "1  ZQ- YIWU HUAHONG CULTURE CREATIVE CO.,LTD         0      1705  \n",
      "2                       NE- NOVUS GMBH CO.KG         1      1190  \n",
      "3         RQ- ROCO BRAND JARIR MARKETING CO.         1      1409  \n",
      "4         RQ- ROCO BRAND JARIR MARKETING CO.         1      1346  \n",
      "\n",
      "Sample customer map:\n",
      "   customer_id  user_idx\n",
      "0        11949         0\n",
      "1        24811         1\n",
      "2        33097         2\n",
      "3        49143         3\n",
      "4        56072         4\n",
      "\n",
      "Sample item map:\n",
      "         stock_code  item_idx\n",
      "0           00-PS20         0\n",
      "1   08-9S714J112633         1\n",
      "2   08-9S714J112691         2\n",
      "3   08-9S714S122214         3\n",
      "4  08-9S71585712206         4\n",
      "Removed 0 rows with missing indices\n",
      "Final interactions shape: (2901, 13)\n",
      "Unique users: 929\n",
      "Unique items: 1735\n",
      "Creating sparse matrix: 929 users × 1735 items\n",
      "Sparse matrix shape: (929, 1735)\n",
      "Non-zero entries: 2786\n",
      "Sparsity: 0.9983\n",
      "\n",
      "Creating train/test split for evaluation...\n",
      "Created 169 test interactions from validation sequences\n",
      "Train matrix shape: (929, 1735)\n",
      "Train non-zero entries: 2786\n",
      "Converting to dense matrix for faster computation...\n",
      "\n",
      "==================================================\n",
      "TRAINING BASELINE MODELS\n",
      "==================================================\n",
      "\n",
      "Training ItemKNN...\n",
      "Training UserKNN...\n",
      "Training Matrix Factorization...\n",
      "Training Popularity Baseline...\n",
      "\n",
      "==================================================\n",
      "DEBUGGING RECOMMENDATIONS\n",
      "==================================================\n",
      "Debugging user 0:\n",
      "User 0 train interactions: [1430 1705]\n",
      "No test interaction found for user 0\n",
      "\n",
      "==================================================\n",
      "EVALUATING BASELINES\n",
      "==================================================\n",
      "\n",
      "Evaluating with held-out interactions...\n",
      "Held-out Interaction Results:\n",
      "ItemKNN: {'Recall@5': 0.0, 'Recall@10': 0.005917159763313609, 'Recall@20': 0.005917159763313609}\n",
      "UserKNN: {'Recall@5': 0.05917159763313609, 'Recall@10': 0.07100591715976332, 'Recall@20': 0.09467455621301775}\n",
      "Matrix Factorization: {'Recall@5': 0.005917159763313609, 'Recall@10': 0.005917159763313609, 'Recall@20': 0.029585798816568046}\n",
      "Popularity: {'Recall@5': 0.047337278106508875, 'Recall@10': 0.10650887573964497, 'Recall@20': 0.14201183431952663}\n",
      "\n",
      "==================================================\n",
      "DATA QUALITY CHECK\n",
      "==================================================\n",
      "Users with interactions: 929/929 (100.00%)\n",
      "Items with interactions: 1735/1735 (100.00%)\n",
      "Total interactions: 2786\n",
      "Average interactions per user: 3.00\n",
      "Average interactions per item: 1.61\n",
      "\n",
      "==================================================\n",
      "PREPARING DATA FOR TWO-TOWER\n",
      "==================================================\n",
      "Saved 7291 interactions for Two-Tower training\n",
      "Interaction strength — mean: 0.58, std: 0.18\n",
      "\n",
      "Saved baseline results to ../data/processed/jarir/baseline_results.json\n",
      "\n",
      "==================================================\n",
      "FINAL SUMMARY\n",
      "==================================================\n",
      "Dataset: Jarir Retail\n",
      "Users: 929\n",
      "Items: 1735\n",
      "Interactions: 2786\n",
      "Sparsity: 0.9983\n",
      "Test interactions: 169\n",
      "\n",
      "Best baseline results (Held-out Interactions):\n",
      "Best: Popularity with Recall@20: 0.1420\n",
      "\n",
      "Data ready for Two-Tower training!\n",
      "Files saved in: ../data/processed/jarir\n"
     ]
    }
   ],
   "source": [
    "# --- Config & Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data paths\n",
    "OUT_DIR = Path('../data/processed/jarir/')\n",
    "INTERACTIONS_TRAIN_PATH = OUT_DIR / 'interactions_clean.parquet'\n",
    "CUSTOMER_MAP_PATH = OUT_DIR / 'customer_id_map.parquet'\n",
    "ITEM_MAP_PATH = OUT_DIR / 'item_id_map.parquet'\n",
    "\n",
    "# Evaluation config\n",
    "K_VALUES = [5, 10, 20]  # Recall@K values to evaluate\n",
    "EVAL_SAMPLE_SIZE = 1000  # Number of users to sample for evaluation\n",
    "\n",
    "print(\"Loading Jarir interaction data...\")\n",
    "\n",
    "# --- Load Processed Data ---\n",
    "# Load sequences\n",
    "seq_train = pd.read_parquet(OUT_DIR / 'sequences_train.parquet', engine=\"fastparquet\")\n",
    "seq_val = pd.read_parquet(OUT_DIR / 'sequences_val.parquet', engine=\"fastparquet\")\n",
    "seq_test = pd.read_parquet(OUT_DIR / 'sequences_test.parquet', engine=\"fastparquet\")\n",
    "\n",
    "# Load maps\n",
    "item_map = pd.read_parquet(OUT_DIR / 'item_id_map.parquet', engine=\"fastparquet\")\n",
    "customer_map = pd.read_parquet(OUT_DIR / 'customer_id_map.parquet', engine=\"fastparquet\")\n",
    "\n",
    "print(f\"Sequences: Train={len(seq_train)}, Val={len(seq_val)}, Test={len(seq_test)}\")\n",
    "print(f\"Items: {len(item_map)}, Customers: {len(customer_map)}\")\n",
    "\n",
    "print(f\"Customers: {len(customer_map)}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nSample interactions:\")\n",
    "print(interactions.head())\n",
    "\n",
    "print(\"\\nSample customer map:\")\n",
    "print(customer_map.head())\n",
    "\n",
    "print(\"\\nSample item map:\")\n",
    "print(item_map.head())\n",
    "\n",
    "# --- Create User and Item Mappings ---\n",
    "# Create lookup dictionaries\n",
    "customer_to_idx = dict(zip(customer_map['customer_id'], customer_map['user_idx']))\n",
    "item_to_idx = dict(zip(item_map['stock_code'], item_map['item_idx']))\n",
    "\n",
    "# Add indices to interactions\n",
    "interactions['user_idx'] = interactions['customer_id'].map(customer_to_idx)\n",
    "interactions['item_idx'] = interactions['stock_code'].map(item_to_idx)\n",
    "\n",
    "# Remove any rows with missing indices\n",
    "before = len(interactions)\n",
    "interactions = interactions.dropna(subset=['user_idx', 'item_idx'])\n",
    "print(f\"Removed {before - len(interactions)} rows with missing indices\")\n",
    "\n",
    "# Convert to integers\n",
    "interactions['user_idx'] = interactions['user_idx'].astype(int)\n",
    "interactions['item_idx'] = interactions['item_idx'].astype(int)\n",
    "\n",
    "print(f\"Final interactions shape: {interactions.shape}\")\n",
    "print(f\"Unique users: {interactions['user_idx'].nunique()}\")\n",
    "print(f\"Unique items: {interactions['item_idx'].nunique()}\")\n",
    "\n",
    "# --- Create Sparse Interaction Matrix ---\n",
    "def create_sparse_matrix_from_sequences(seq_df, n_users, n_items):\n",
    "    \"\"\"Create sparse matrix from sequences for training\"\"\"\n",
    "    rows = []\n",
    "    cols = []\n",
    "    values = []\n",
    "    \n",
    "    for _, row in seq_df.iterrows():\n",
    "        user_idx = row['user_idx']\n",
    "        pos_item_idx = row['pos_item_idx']\n",
    "        \n",
    "        # Add positive interaction\n",
    "        rows.append(user_idx)\n",
    "        cols.append(pos_item_idx)\n",
    "        values.append(1.0)\n",
    "        \n",
    "        # Add history interactions\n",
    "        if pd.notna(row['history_idx']) and row['history_idx']:\n",
    "            hist_items = [int(x) for x in row['history_idx'].split()]\n",
    "            for hist_item in hist_items:\n",
    "                rows.append(user_idx)\n",
    "                cols.append(hist_item)\n",
    "                values.append(0.5)  # Lower weight for history\n",
    "    \n",
    "    matrix = csr_matrix((values, (rows, cols)), shape=(n_users, n_items))\n",
    "    return matrix\n",
    "\n",
    "# Create training matrix from sequences\n",
    "train_matrix = create_sparse_matrix_from_sequences(seq_train, len(customer_map), len(item_map))\n",
    "\n",
    "n_users = len(customer_map)\n",
    "n_items = len(item_map)\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def create_sparse_matrix(df, n_users, n_items):\n",
    "    rows = df['user_idx'].astype(int).values\n",
    "    cols = df['item_idx'].astype(int).values\n",
    "    # if you have an interaction strength column, use it; otherwise default to 1.0\n",
    "    data = df.get('interaction_strength', pd.Series(1.0, index=df.index)).values\n",
    "    return csr_matrix((data, (rows, cols)), shape=(n_users, n_items))\n",
    "\n",
    "\n",
    "print(f\"Creating sparse matrix: {n_users} users × {n_items} items\")\n",
    "\n",
    "full_matrix = create_sparse_matrix(interactions, n_users, n_items)\n",
    "\n",
    "print(f\"Sparse matrix shape: {full_matrix.shape}\")\n",
    "print(f\"Non-zero entries: {full_matrix.nnz}\")\n",
    "print(f\"Sparsity: {1 - full_matrix.nnz / (n_users * n_items):.4f}\")\n",
    "\n",
    "# --- Create Train/Test Split for Proper Evaluation ---\n",
    "print(\"\\nCreating train/test split for evaluation...\")\n",
    "np.random.seed(42)\n",
    "test_interactions = []\n",
    "\n",
    "# Use validation sequences for evaluation\n",
    "test_interactions = []\n",
    "for _, row in seq_val.iterrows():\n",
    "    user_idx = row['user_idx']\n",
    "    test_item = row['pos_item_idx']\n",
    "    test_interactions.append((user_idx, test_item, 1.0))\n",
    "    \n",
    "    # Remove test interaction from training matrix\n",
    "    train_matrix[user_idx, test_item] = 0\n",
    "\n",
    "print(f\"Created {len(test_interactions)} test interactions from validation sequences\")\n",
    "\n",
    "\n",
    "# Create train matrix (with test interactions removed)\n",
    "train_matrix = full_matrix.copy()\n",
    "\n",
    "print(f\"Train matrix shape: {train_matrix.shape}\")\n",
    "print(f\"Train non-zero entries: {train_matrix.nnz}\")\n",
    "\n",
    "# Convert to dense if matrix is small enough\n",
    "if n_users * n_items < 1e7:  # 10M elements threshold\n",
    "    print(\"Converting to dense matrix for faster computation...\")\n",
    "    train_matrix_dense = train_matrix.toarray()\n",
    "    use_dense = True\n",
    "else:\n",
    "    train_matrix_dense = None\n",
    "    use_dense = False\n",
    "\n",
    "# --- Baseline Models ---\n",
    "\n",
    "class SimpleItemKNN:\n",
    "    \"\"\"Simple ItemKNN baseline using cosine similarity\"\"\"\n",
    "    def __init__(self, k=50):\n",
    "        self.k = k\n",
    "        self.item_similarities = None\n",
    "        self.train_matrix = None\n",
    "    \n",
    "    def fit(self, matrix):\n",
    "        self.train_matrix = matrix\n",
    "        # Compute item-item similarities\n",
    "        if use_dense:\n",
    "            # Use dense matrix for small datasets\n",
    "            item_similarities = cosine_similarity(matrix.T)\n",
    "        else:\n",
    "            # Use sparse matrix for large datasets\n",
    "            item_similarities = cosine_similarity(matrix.T.toarray())\n",
    "        \n",
    "        self.item_similarities = item_similarities\n",
    "        return self\n",
    "    \n",
    "    def predict(self, user_idx, n_recommendations=10):\n",
    "        if user_idx >= self.train_matrix.shape[0]:\n",
    "            return []\n",
    "        \n",
    "        # Get user's interactions - FIXED FOR SPARSE MATRICES\n",
    "        if hasattr(self.train_matrix, 'toarray'):\n",
    "            # Sparse matrix\n",
    "            user_interactions = self.train_matrix[user_idx].toarray().flatten()\n",
    "        else:\n",
    "            # Dense matrix\n",
    "            user_interactions = self.train_matrix[user_idx]\n",
    "        \n",
    "        # Find items user has interacted with - NOW SAFE\n",
    "        interacted_items = np.where(user_interactions > 0)[0]\n",
    "        \n",
    "        if len(interacted_items) == 0:\n",
    "            return []\n",
    "        \n",
    "        # Compute scores for all items - SIMPLIFIED APPROACH\n",
    "        scores = np.zeros(self.train_matrix.shape[1])\n",
    "        \n",
    "        for item in interacted_items:\n",
    "            # Get top-k similar items\n",
    "            similar_items = np.argsort(self.item_similarities[item])[::-1][:self.k]\n",
    "            for similar_item in similar_items:\n",
    "                if similar_item not in interacted_items:  # Don't recommend already interacted items\n",
    "                    # Just add similarity score, don't multiply by interaction strength\n",
    "                    scores[similar_item] += self.item_similarities[item][similar_item]\n",
    "        \n",
    "        # Return top recommendations - REMOVE THE > 0 FILTER\n",
    "        top_items = np.argsort(scores)[::-1][:n_recommendations]\n",
    "        return [item for item in top_items if scores[item] > 0]\n",
    "\n",
    "class SimpleUserKNN:\n",
    "    \"\"\"Simple UserKNN baseline using cosine similarity\"\"\"\n",
    "    def __init__(self, k=50):\n",
    "        self.k = k\n",
    "        self.user_similarities = None\n",
    "        self.train_matrix = None\n",
    "    \n",
    "    def fit(self, matrix):\n",
    "        self.train_matrix = matrix\n",
    "        # Compute user-user similarities\n",
    "        if use_dense:\n",
    "            user_similarities = cosine_similarity(matrix)\n",
    "        else:\n",
    "            user_similarities = cosine_similarity(matrix.toarray())\n",
    "        \n",
    "        self.user_similarities = user_similarities\n",
    "        return self\n",
    "    \n",
    "    def predict(self, user_idx, n_recommendations=10):\n",
    "        if user_idx >= self.train_matrix.shape[0]:\n",
    "            return []\n",
    "        \n",
    "        # Get similar users - INCLUDE SELF TOO\n",
    "        similar_users = np.argsort(self.user_similarities[user_idx])[::-1][:self.k+1]  # Include self\n",
    "        \n",
    "        # Aggregate recommendations from similar users\n",
    "        scores = np.zeros(self.train_matrix.shape[1])\n",
    "        \n",
    "        for similar_user in similar_users:\n",
    "            # Get similar user's interactions - FIXED FOR SPARSE MATRICES\n",
    "            if hasattr(self.train_matrix, 'toarray'):\n",
    "                # Sparse matrix\n",
    "                similar_user_interactions = self.train_matrix[similar_user].toarray().flatten()\n",
    "            else:\n",
    "                # Dense matrix\n",
    "                similar_user_interactions = self.train_matrix[similar_user]\n",
    "            \n",
    "            # Add weighted scores - REMOVE SIMILARITY WEIGHT FOR NOW\n",
    "            scores += similar_user_interactions  # Just sum interactions\n",
    "        \n",
    "        # Get user's own interactions to exclude - FIXED FOR SPARSE MATRICES\n",
    "        if hasattr(self.train_matrix, 'toarray'):\n",
    "            # Sparse matrix\n",
    "            user_interactions = self.train_matrix[user_idx].toarray().flatten()\n",
    "        else:\n",
    "            # Dense matrix\n",
    "            user_interactions = self.train_matrix[user_idx]\n",
    "        \n",
    "        interacted_items = np.where(user_interactions > 0)[0]\n",
    "        \n",
    "        # Zero out already interacted items\n",
    "        scores[interacted_items] = -1\n",
    "        \n",
    "        # Return top recommendations - REMOVE THE > 0 FILTER\n",
    "        top_items = np.argsort(scores)[::-1][:n_recommendations]\n",
    "        return [item for item in top_items if scores[item] > -0.5]  # Allow small negative scores\n",
    "\n",
    "class SimpleMatrixFactorization:\n",
    "    \"\"\"Simple Matrix Factorization using NMF\"\"\"\n",
    "    def __init__(self, n_factors=50, max_iter=100):\n",
    "        self.n_factors = n_factors\n",
    "        self.max_iter = max_iter\n",
    "        self.model = None\n",
    "        self.train_matrix = None\n",
    "    \n",
    "    def fit(self, matrix):\n",
    "        self.train_matrix = matrix\n",
    "        \n",
    "        # Convert to dense for NMF\n",
    "        if use_dense:\n",
    "            matrix_dense = matrix\n",
    "        else:\n",
    "            matrix_dense = matrix.toarray()\n",
    "        \n",
    "        # Apply NMF\n",
    "        self.model = NMF(n_components=self.n_factors, max_iter=self.max_iter, random_state=42)\n",
    "        self.model.fit(matrix_dense)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, user_idx, n_recommendations=10):\n",
    "        if user_idx >= self.train_matrix.shape[0] or self.model is None:\n",
    "            return []\n",
    "        \n",
    "        # Get user's interactions to exclude - FIXED FOR SPARSE MATRICES\n",
    "        if hasattr(self.train_matrix, 'toarray'):\n",
    "            # Sparse matrix\n",
    "            user_interactions = self.train_matrix[user_idx].toarray().flatten()\n",
    "        else:\n",
    "            # Dense matrix\n",
    "            user_interactions = self.train_matrix[user_idx]\n",
    "        \n",
    "        interacted_items = np.where(user_interactions > 0)[0]\n",
    "        \n",
    "        # Get predicted scores\n",
    "        user_factors = self.model.transform(self.train_matrix[user_idx:user_idx+1])\n",
    "        item_factors = self.model.components_\n",
    "        \n",
    "        scores = np.dot(user_factors, item_factors).flatten()\n",
    "        \n",
    "        # Zero out already interacted items\n",
    "        scores[interacted_items] = -1\n",
    "        \n",
    "        # Return top recommendations - REMOVE THE > 0 FILTER\n",
    "        top_items = np.argsort(scores)[::-1][:n_recommendations]\n",
    "        return [item for item in top_items if scores[item] > -0.5]  # Allow small negative scores\n",
    "\n",
    "class PopularityBaseline:\n",
    "    \"\"\"Simple popularity-based baseline\"\"\"\n",
    "    def __init__(self):\n",
    "        self.item_popularity = None\n",
    "        self.train_matrix = None\n",
    "    \n",
    "    def fit(self, matrix):\n",
    "        self.train_matrix = matrix\n",
    "        # Compute item popularity (sum of interactions)\n",
    "        self.item_popularity = np.array(matrix.sum(axis=0)).flatten()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, user_idx, n_recommendations=10):\n",
    "        if user_idx >= self.train_matrix.shape[0]:\n",
    "            return []\n",
    "        \n",
    "        # Get user's interactions to exclude\n",
    "        if hasattr(self.train_matrix, 'toarray'):\n",
    "            user_interactions = self.train_matrix[user_idx].toarray().flatten()\n",
    "        else:\n",
    "            user_interactions = self.train_matrix[user_idx]\n",
    "        \n",
    "        interacted_items = np.where(user_interactions > 0)[0]\n",
    "        \n",
    "        # Use popularity scores\n",
    "        scores = self.item_popularity.copy()\n",
    "        scores[interacted_items] = -1  # Exclude already interacted items\n",
    "        \n",
    "        # Return top recommendations\n",
    "        top_items = np.argsort(scores)[::-1][:n_recommendations]\n",
    "        return [item for item in top_items if scores[item] > 0]\n",
    "\n",
    "# --- Evaluation Functions ---\n",
    "\n",
    "def evaluate_with_held_out_interactions(model, train_matrix, test_interactions, k_values=[5, 10, 20]):\n",
    "    \"\"\"Evaluate model using held-out interactions\"\"\"\n",
    "    results = {k: [] for k in k_values}\n",
    "    \n",
    "    for user_idx, test_item, test_value in test_interactions:\n",
    "        # Get recommendations\n",
    "        recommendations = model.predict(user_idx, n_recommendations=max(k_values))\n",
    "        \n",
    "        # Compute Recall@K for each K\n",
    "        for k in k_values:\n",
    "            if len(recommendations) >= k:\n",
    "                recommended_items = set(recommendations[:k])\n",
    "                # Check if test item is in recommendations\n",
    "                if test_item in recommended_items:\n",
    "                    results[k].append(1.0)\n",
    "                else:\n",
    "                    results[k].append(0.0)\n",
    "            else:\n",
    "                results[k].append(0.0)\n",
    "    \n",
    "    # Compute average Recall@K\n",
    "    avg_results = {}\n",
    "    for k in k_values:\n",
    "        if results[k]:\n",
    "            avg_results[f'Recall@{k}'] = np.mean(results[k])\n",
    "        else:\n",
    "            avg_results[f'Recall@{k}'] = 0.0\n",
    "    \n",
    "    return avg_results\n",
    "\n",
    "# --- Train and Evaluate Baselines ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING BASELINE MODELS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Train ItemKNN\n",
    "print(\"\\nTraining ItemKNN...\")\n",
    "itemknn = SimpleItemKNN(k=50)\n",
    "itemknn.fit(train_matrix)\n",
    "\n",
    "# Train UserKNN\n",
    "print(\"Training UserKNN...\")\n",
    "userknn = SimpleUserKNN(k=50)\n",
    "userknn.fit(train_matrix)\n",
    "\n",
    "# Train Matrix Factorization\n",
    "print(\"Training Matrix Factorization...\")\n",
    "mf = SimpleMatrixFactorization(n_factors=50, max_iter=100)\n",
    "mf.fit(train_matrix)\n",
    "\n",
    "# Train Popularity Baseline\n",
    "print(\"Training Popularity Baseline...\")\n",
    "pop_baseline = PopularityBaseline()\n",
    "pop_baseline.fit(train_matrix)\n",
    "\n",
    "# --- Debug: Check one user's recommendations ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DEBUGGING RECOMMENDATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "test_user = 0\n",
    "print(f\"Debugging user {test_user}:\")\n",
    "user_interactions = train_matrix[test_user].toarray().flatten()\n",
    "interacted_items = np.where(user_interactions > 0)[0]\n",
    "print(f\"User {test_user} train interactions: {interacted_items}\")\n",
    "\n",
    "# Find test interaction for this user\n",
    "test_item_for_user = None\n",
    "for user_idx, test_item, test_value in test_interactions:\n",
    "    if user_idx == test_user:\n",
    "        test_item_for_user = test_item\n",
    "        break\n",
    "\n",
    "if test_item_for_user is not None:\n",
    "    print(f\"User {test_user} test item: {test_item_for_user}\")\n",
    "    \n",
    "    # Test ItemKNN\n",
    "    itemknn_recs = itemknn.predict(test_user, 10)\n",
    "    print(f\"ItemKNN recommendations: {itemknn_recs}\")\n",
    "    print(f\"ItemKNN count: {len(itemknn_recs)}\")\n",
    "    print(f\"Test item in ItemKNN recs: {test_item_for_user in itemknn_recs}\")\n",
    "    \n",
    "    # Test UserKNN  \n",
    "    userknn_recs = userknn.predict(test_user, 10)\n",
    "    print(f\"UserKNN recommendations: {userknn_recs}\")\n",
    "    print(f\"UserKNN count: {len(userknn_recs)}\")\n",
    "    print(f\"Test item in UserKNN recs: {test_item_for_user in userknn_recs}\")\n",
    "    \n",
    "    # Test MF\n",
    "    mf_recs = mf.predict(test_user, 10)\n",
    "    print(f\"MF recommendations: {mf_recs}\")\n",
    "    print(f\"MF count: {len(mf_recs)}\")\n",
    "    print(f\"Test item in MF recs: {test_item_for_user in mf_recs}\")\n",
    "    \n",
    "    # Test Popularity\n",
    "    pop_recs = pop_baseline.predict(test_user, 10)\n",
    "    print(f\"Popularity recommendations: {pop_recs}\")\n",
    "    print(f\"Popularity count: {len(pop_recs)}\")\n",
    "    print(f\"Test item in Popularity recs: {test_item_for_user in pop_recs}\")\n",
    "else:\n",
    "    print(f\"No test interaction found for user {test_user}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EVALUATING BASELINES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Evaluate with held-out interactions\n",
    "print(\"\\nEvaluating with held-out interactions...\")\n",
    "itemknn_results = evaluate_with_held_out_interactions(itemknn, train_matrix, test_interactions, k_values=K_VALUES)\n",
    "userknn_results = evaluate_with_held_out_interactions(userknn, train_matrix, test_interactions, k_values=K_VALUES)\n",
    "mf_results = evaluate_with_held_out_interactions(mf, train_matrix, test_interactions, k_values=K_VALUES)\n",
    "pop_results = evaluate_with_held_out_interactions(pop_baseline, train_matrix, test_interactions, k_values=K_VALUES)\n",
    "\n",
    "print(\"Held-out Interaction Results:\")\n",
    "print(f\"ItemKNN: {itemknn_results}\")\n",
    "print(f\"UserKNN: {userknn_results}\")\n",
    "print(f\"Matrix Factorization: {mf_results}\")\n",
    "print(f\"Popularity: {pop_results}\")\n",
    "\n",
    "# --- Data Quality Check ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Count users and items with interactions\n",
    "n_users_with_interactions = (train_matrix.sum(axis=1) > 0).sum()\n",
    "n_items_with_interactions = (train_matrix.sum(axis=0) > 0).sum()\n",
    "\n",
    "print(f\"Users with interactions: {n_users_with_interactions}/{n_users} ({n_users_with_interactions/n_users:.2%})\")\n",
    "print(f\"Items with interactions: {n_items_with_interactions}/{n_items} ({n_items_with_interactions/n_items:.2%})\")\n",
    "\n",
    "# Check user overlap\n",
    "print(f\"Total interactions: {train_matrix.nnz}\")\n",
    "print(f\"Average interactions per user: {train_matrix.nnz / n_users:.2f}\")\n",
    "print(f\"Average interactions per item: {train_matrix.nnz / n_items:.2f}\")\n",
    "\n",
    "# --- Prepare Data for Two-Tower ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PREPARING DATA FOR TWO-TOWER\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- Prepare data for Two-Tower training ---\n",
    "interactions_for_twotower = []\n",
    "\n",
    "for _, row in seq_train.iterrows():\n",
    "    user_idx     = row['user_idx']\n",
    "    pos_item_idx = row['pos_item_idx']\n",
    "    \n",
    "    # add the positive interaction\n",
    "    interactions_for_twotower.append({\n",
    "        'user_idx':               user_idx,\n",
    "        'item_idx':               pos_item_idx,\n",
    "        'interaction_strength':   1.0\n",
    "    })\n",
    "    \n",
    "    # add any history items as \"negatives\" with lower weight\n",
    "    if pd.notna(row.get('history_idx')) and row['history_idx']:\n",
    "        hist_items = [int(x) for x in row['history_idx'].split()]\n",
    "        for hist_item in hist_items:\n",
    "            interactions_for_twotower.append({\n",
    "                'user_idx':             user_idx,\n",
    "                'item_idx':             hist_item,\n",
    "                'interaction_strength': 0.5\n",
    "            })\n",
    "\n",
    "# build the DataFrame\n",
    "interactions_for_twotower = pd.DataFrame(interactions_for_twotower)\n",
    "\n",
    "# normalize interaction_strength\n",
    "mean_strength = interactions_for_twotower['interaction_strength'].mean()\n",
    "std_strength  = interactions_for_twotower['interaction_strength'].std()\n",
    "\n",
    "interactions_for_twotower['interaction_strength_norm'] = (\n",
    "    (interactions_for_twotower['interaction_strength'] - mean_strength)\n",
    "    / std_strength\n",
    ")\n",
    "\n",
    "# save to disk\n",
    "interactions_for_twotower.to_parquet(\n",
    "    OUT_DIR / 'interactions_twotower.parquet',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(f\"Saved {len(interactions_for_twotower)} interactions for Two-Tower training\")\n",
    "print(f\"Interaction strength — mean: {mean_strength:.2f}, std: {std_strength:.2f}\")\n",
    "\n",
    "# --- Save Baseline Results ---\n",
    "\n",
    "baseline_results = {\n",
    "    'held_out_interactions': {\n",
    "        'ItemKNN': itemknn_results,\n",
    "        'UserKNN': userknn_results,\n",
    "        'MatrixFactorization': mf_results,\n",
    "        'Popularity': pop_results\n",
    "    },\n",
    "    'data_stats': {\n",
    "        'n_users': n_users,\n",
    "        'n_items': n_items,\n",
    "        'n_interactions': train_matrix.nnz,\n",
    "        'sparsity': 1 - train_matrix.nnz / (n_users * n_items),\n",
    "        'n_test_interactions': len(test_interactions)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(OUT_DIR / 'baseline_results.json', 'w') as f:\n",
    "    json.dump(baseline_results, f, indent=2)\n",
    "\n",
    "print(f\"\\nSaved baseline results to {OUT_DIR / 'baseline_results.json'}\")\n",
    "\n",
    "# --- Final Summary ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Dataset: Jarir Retail\")\n",
    "print(f\"Users: {n_users}\")\n",
    "print(f\"Items: {n_items}\")\n",
    "print(f\"Interactions: {train_matrix.nnz}\")\n",
    "print(f\"Sparsity: {1 - train_matrix.nnz / (n_users * n_items):.4f}\")\n",
    "print(f\"Test interactions: {len(test_interactions)}\")\n",
    "\n",
    "print(f\"\\nBest baseline results (Held-out Interactions):\")\n",
    "best_model = max([\n",
    "    ('ItemKNN', itemknn_results[f'Recall@{K_VALUES[-1]}']),\n",
    "    ('UserKNN', userknn_results[f'Recall@{K_VALUES[-1]}']),\n",
    "    ('MatrixFactorization', mf_results[f'Recall@{K_VALUES[-1]}']),\n",
    "    ('Popularity', pop_results[f'Recall@{K_VALUES[-1]}'])\n",
    "], key=lambda x: x[1])\n",
    "print(f\"Best: {best_model[0]} with Recall@{K_VALUES[-1]}: {best_model[1]:.4f}\")\n",
    "\n",
    "print(f\"\\nData ready for Two-Tower training!\")\n",
    "print(f\"Files saved in: {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb8273-c56d-4881-80d1-121e7e1a8a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bdca01-8db5-4fe6-966f-85bc12c1f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETRIEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5780a61d-450d-4455-8b88-ceb6d4e36060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Configuration:\n",
      "  d_model: 256\n",
      "  batch_size: 512\n",
      "  accum_steps: 2\n",
      "  epochs: 50\n",
      "  patience: 6\n",
      "  lr: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout: 0.2\n",
      "  eval_topk: 10\n",
      "  eval_sample: None\n",
      "  seed: 42\n",
      "  k_neg: 50\n",
      "  fixed_logit_scale: 10.0\n",
      "\n",
      "Loading data...\n",
      "Sequences: Train=1108, Val=169\n",
      "Items: 1735, Customers: 929\n",
      "\n",
      "Sample interactions:\n",
      "   customer_id invoice_date      stock_code  \\\n",
      "0        11949   2024-12-09       RQ-CHB002   \n",
      "1        11949   2024-12-09   ZQ-F27318BGLD   \n",
      "2        24811   2024-09-12      NE-0230059   \n",
      "3        24811   2024-10-08  RQ-A42DR05VWHT   \n",
      "4        24811   2024-11-18       RQ-193024   \n",
      "\n",
      "                                    description  quantity    price  \\\n",
      "0         RQ-CHB002 CERTIFICATE HOLDER PVC BLUE      10.0   15.304   \n",
      "1          ZQ-F27318BGLD CERTIFICATE FRAME GOLD       5.0   27.132   \n",
      "2      NE-0230059 STAPLER HEAVY DUTY B56 200 SH       1.0  402.780   \n",
      "3  RQ-A42DR05VWHT BINDER 2D 0.5\"RING/1.25\"SPINE       8.0   10.435   \n",
      "4           RQ-193024 CRAYON WAX 24 COL REGULAR      15.0    4.174   \n",
      "\n",
      "   line_amount     country        brand               category  \\\n",
      "0       153.04  0103-PLAZA         Roco  IN02  OFFICE SUPPLIES   \n",
      "1       135.66  0103-PLAZA  Non Branded  IN02  OFFICE SUPPLIES   \n",
      "2       402.78  0103-PLAZA        Novus  IN02  OFFICE SUPPLIES   \n",
      "3        83.48  0103-PLAZA         Roco  IN02  OFFICE SUPPLIES   \n",
      "4        62.61  0103-PLAZA         Roco  IN01  SCHOOL SUPPLIES   \n",
      "\n",
      "                                      vendor  user_idx  item_idx  \n",
      "0         RQ- ROCO BRAND JARIR MARKETING CO.         0      1430  \n",
      "1  ZQ- YIWU HUAHONG CULTURE CREATIVE CO.,LTD         0      1705  \n",
      "2                       NE- NOVUS GMBH CO.KG         1      1190  \n",
      "3         RQ- ROCO BRAND JARIR MARKETING CO.         1      1409  \n",
      "4         RQ- ROCO BRAND JARIR MARKETING CO.         1      1346  \n",
      "\n",
      "Baseline results:\n",
      "  ItemKNN: {'Recall@5': 0.0, 'Recall@10': 0.005917159763313609, 'Recall@20': 0.005917159763313609}\n",
      "  UserKNN: {'Recall@5': 0.05917159763313609, 'Recall@10': 0.07100591715976332, 'Recall@20': 0.09467455621301775}\n",
      "  MatrixFactorization: {'Recall@5': 0.005917159763313609, 'Recall@10': 0.005917159763313609, 'Recall@20': 0.029585798816568046}\n",
      "  Popularity: {'Recall@5': 0.047337278106508875, 'Recall@10': 0.10650887573964497, 'Recall@20': 0.14201183431952663}\n",
      "\n",
      "Creating train/validation split...\n",
      "Train sequences: 1108\n",
      "Val sequences: 169\n",
      "Train batches: 3\n",
      "Val batches: 1\n",
      "\n",
      "Initializing Two-Tower model...\n",
      "Model parameters: 947,200\n",
      "\n",
      "==================================================\n",
      "TRAINING TWO-TOWER MODEL\n",
      "==================================================\n",
      "Epoch 10/50: Loss=4.1801, Recall@10=0.0473\n",
      "Early stopping at epoch 14\n",
      "\n",
      "Best Recall@10: 0.0473\n",
      "\n",
      "Loading best model for final evaluation...\n",
      "Final Recall@10: 0.0473\n",
      "\n",
      "Saving embeddings...\n",
      "Saved user embeddings: (929, 256)\n",
      "Saved item embeddings: (1735, 256)\n",
      "\n",
      "==================================================\n",
      "COMPARISON WITH BASELINES\n",
      "==================================================\n",
      "Best baseline (Popularity): Recall@10 = 0.1065\n",
      "Two-Tower model: Recall@10 = 0.0473\n",
      "Improvement: -55.56%\n",
      "\n",
      "Saved results to ../data/processed/jarir/twotower_results.json\n",
      "\n",
      "==================================================\n",
      "FINAL SUMMARY\n",
      "==================================================\n",
      "Dataset: Jarir Retail\n",
      "Model: Two-Tower (Interaction-based)\n",
      "Embedding dimension: 256\n",
      "Training epochs: 14\n",
      "Best Recall@10: 0.0473\n",
      "Final Recall@10: 0.0473\n",
      "Improvement over best baseline: -55.56%\n",
      "\n",
      "Files saved:\n",
      "  - best_twotower_model.pth\n",
      "  - user_embeddings.npy\n",
      "  - item_embeddings.npy\n",
      "  - twotower_results.json\n",
      "\n",
      "Model ready for inference!\n"
     ]
    }
   ],
   "source": [
    "# --- Config & Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data paths\n",
    "OUT_DIR = Path('../data/processed/jarir/')\n",
    "INTERACTIONS_PATH = OUT_DIR / 'interactions_twotower.parquet'\n",
    "CUSTOMER_MAP_PATH = OUT_DIR / 'customer_id_map.parquet'\n",
    "ITEM_MAP_PATH = OUT_DIR / 'item_id_map.parquet'\n",
    "BASELINE_RESULTS_PATH = OUT_DIR / 'baseline_results.json'\n",
    "\n",
    "# Model configuration\n",
    "CFG = {\n",
    "    \"d_model\": 256,  # embedding dim (shared space)\n",
    "    \"batch_size\": 512,  # per-step batch\n",
    "    \"accum_steps\": 2,  # gradient accumulation\n",
    "    \"epochs\": 50,\n",
    "    \"patience\": 6,  # early stop on Recall@K\n",
    "    \"lr\": 5e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"dropout\": 0.2,\n",
    "    \"eval_topk\": 10,  # Recall@10\n",
    "    \"eval_sample\": None,  # None = full validation\n",
    "    \"seed\": 42,\n",
    "    \"k_neg\": 50,  # negatives per example\n",
    "    \"fixed_logit_scale\": 10.0  # temperature scale for logits\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CFG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(CFG['seed'])\n",
    "np.random.seed(CFG['seed'])\n",
    "\n",
    "# --- Load Data ---\n",
    "print(\"\\nLoading data...\")\n",
    "\n",
    "# Load sequences\n",
    "seq_train = pd.read_parquet(OUT_DIR / 'sequences_train.parquet', engine=\"fastparquet\")\n",
    "seq_val = pd.read_parquet(OUT_DIR / 'sequences_val.parquet', engine=\"fastparquet\")\n",
    "\n",
    "# Load maps\n",
    "item_map = pd.read_parquet(OUT_DIR / 'item_id_map.parquet', engine=\"fastparquet\")\n",
    "customer_map = pd.read_parquet(OUT_DIR / 'customer_id_map.parquet', engine=\"fastparquet\")\n",
    "\n",
    "print(f\"Sequences: Train={len(seq_train)}, Val={len(seq_val)}\")\n",
    "print(f\"Items: {len(item_map)}, Customers: {len(customer_map)}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nSample interactions:\")\n",
    "print(interactions.head())\n",
    "\n",
    "# Load baseline results\n",
    "with open(BASELINE_RESULTS_PATH, 'r') as f:\n",
    "    baseline_results = json.load(f)\n",
    "\n",
    "print(\"\\nBaseline results:\")\n",
    "for model, results in baseline_results['held_out_interactions'].items():\n",
    "    print(f\"  {model}: {results}\")\n",
    "\n",
    "# --- Create Train/Validation Split ---\n",
    "print(\"\\nCreating train/validation split...\")\n",
    "\n",
    "# Create train/val split by user_idx (to avoid data leakage)\n",
    "np.random.seed(CFG['seed'])\n",
    "user_ids = interactions['user_idx'].unique()\n",
    "val_users = np.random.choice(user_ids, size=len(user_ids)//5, replace=False)\n",
    "\n",
    "# Use pre-split sequences\n",
    "train_interactions = seq_train.copy()\n",
    "val_interactions = seq_val.copy()\n",
    "\n",
    "print(f\"Train sequences: {len(train_interactions)}\")\n",
    "print(f\"Val sequences: {len(val_interactions)}\")\n",
    "\n",
    "# --- Two-Tower Model Architecture ---\n",
    "\n",
    "class TwoTowerModel(nn.Module):\n",
    "    \"\"\"Two-Tower model for interaction-based recommendations\"\"\"\n",
    "    \n",
    "    def __init__(self, n_users, n_items, d_model=256, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # User tower\n",
    "        self.user_embedding = nn.Embedding(n_users, d_model)\n",
    "        self.user_mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Item tower\n",
    "        self.item_embedding = nn.Embedding(n_items, d_model)\n",
    "        self.item_mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Initialize embeddings\n",
    "        nn.init.normal_(self.user_embedding.weight, mean=0.0, std=0.1)\n",
    "        nn.init.normal_(self.item_embedding.weight, mean=0.0, std=0.1)\n",
    "    \n",
    "    def user_vec(self, user_ids):\n",
    "        \"\"\"Get user embeddings\"\"\"\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        user_vec = self.user_mlp(user_emb)\n",
    "        return F.normalize(user_vec, p=2, dim=1)\n",
    "    \n",
    "    def item_vec(self, item_ids):\n",
    "        \"\"\"Get item embeddings\"\"\"\n",
    "        item_emb = self.item_embedding(item_ids)\n",
    "        item_vec = self.item_mlp(item_emb)\n",
    "        return F.normalize(item_vec, p=2, dim=1)\n",
    "    \n",
    "    def forward(self, user_ids, pos_item_ids, neg_item_ids=None):\n",
    "        \"\"\"Forward pass with optional negative sampling\"\"\"\n",
    "        user_vec = self.user_vec(user_ids)\n",
    "        pos_item_vec = self.item_vec(pos_item_ids)\n",
    "        \n",
    "        # Positive scores\n",
    "        pos_scores = torch.sum(user_vec * pos_item_vec, dim=1) * CFG['fixed_logit_scale']\n",
    "        \n",
    "        if neg_item_ids is not None:\n",
    "            neg_item_vec = self.item_vec(neg_item_ids)\n",
    "            neg_scores = torch.sum(user_vec.unsqueeze(1) * neg_item_vec, dim=2) * CFG['fixed_logit_scale']\n",
    "            return pos_scores, neg_scores\n",
    "        else:\n",
    "            return pos_scores\n",
    "\n",
    "# --- Dataset and DataLoader ---\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, sequences, n_items, k_neg=50):\n",
    "        self.sequences = sequences\n",
    "        self.n_items    = n_items\n",
    "        self.k_neg      = k_neg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.sequences.iloc[idx]\n",
    "        user_id     = row['user_idx']\n",
    "        pos_item_id = row['pos_item_idx']\n",
    "        \n",
    "        # parse history list\n",
    "        hist_items = []\n",
    "        if pd.notna(row['history_idx']) and row['history_idx']:\n",
    "            hist_items = [int(x) for x in row['history_idx'].split()]\n",
    "\n",
    "        # sample negatives (avoid history + pos)\n",
    "        available = list(set(range(self.n_items)) - set(hist_items) - {pos_item_id})\n",
    "        if len(available) >= self.k_neg:\n",
    "            neg_ids = np.random.choice(available, self.k_neg, replace=False)\n",
    "        else:\n",
    "            neg_ids = np.random.choice(self.n_items, self.k_neg, replace=False)\n",
    "\n",
    "        return {\n",
    "            'user_id':      torch.tensor(user_id, dtype=torch.long),\n",
    "            'history_items':torch.tensor(hist_items, dtype=torch.long),\n",
    "            'pos_item_id':  torch.tensor(pos_item_id, dtype=torch.long),\n",
    "            'neg_item_ids': torch.tensor(neg_ids, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SequenceDataset(train_interactions, len(item_map), CFG['k_neg'])\n",
    "val_dataset = SequenceDataset(val_interactions, len(item_map), CFG['k_neg'])\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # batch is a list of dicts\n",
    "    user_ids      = torch.stack([b['user_id']      for b in batch])\n",
    "    pos_item_ids  = torch.stack([b['pos_item_id']  for b in batch])\n",
    "    neg_item_ids  = torch.stack([b['neg_item_ids'] for b in batch])\n",
    "    \n",
    "    # pad histories to max length in this batch\n",
    "    histories = [b['history_items'] for b in batch]\n",
    "    histories_padded = pad_sequence(histories, batch_first=True, padding_value=0)\n",
    "    # also build a mask if you need it later\n",
    "    history_mask = (histories_padded != 0)\n",
    "    \n",
    "    return {\n",
    "        'user_id':       user_ids,\n",
    "        'history_items': histories_padded,\n",
    "        'history_mask':  history_mask,\n",
    "        'pos_item_id':   pos_item_ids,\n",
    "        'neg_item_ids':  neg_item_ids,\n",
    "    }\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CFG['batch_size'],\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,   # <— here\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CFG['batch_size'],\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,   # <— and here\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "\n",
    "# --- Initialize Model ---\n",
    "print(\"\\nInitializing Two-Tower model...\")\n",
    "\n",
    "model = TwoTowerModel(\n",
    "    n_users=len(customer_map),\n",
    "    n_items=len(item_map),\n",
    "    d_model=CFG['d_model'],\n",
    "    dropout=CFG['dropout']\n",
    ").to(device)\n",
    "\n",
    "# Compile model for faster training (if available)\n",
    "if hasattr(torch, 'compile'):\n",
    "    model = torch.compile(model)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# --- Training Setup ---\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=CFG['lr'], \n",
    "    weight_decay=CFG['weight_decay']\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max', \n",
    "    factor=0.5, \n",
    "    patience=3\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "def in_batch_negative_loss(pos_scores, neg_scores):\n",
    "    \"\"\"In-batch negative loss\"\"\"\n",
    "    # Combine positive and negative scores\n",
    "    all_scores = torch.cat([pos_scores.unsqueeze(1), neg_scores], dim=1)\n",
    "    \n",
    "    # Cross-entropy loss\n",
    "    labels = torch.zeros(pos_scores.size(0), dtype=torch.long, device=device)\n",
    "    loss = F.cross_entropy(all_scores, labels)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# --- Evaluation Function ---\n",
    "def evaluate_recall_at_k(model, val_loader, k=10, n_samples=None):\n",
    "    \"\"\"Evaluate Recall@K on validation sequences\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_recalls = []\n",
    "    sample_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            if n_samples and sample_count >= n_samples:\n",
    "                break\n",
    "                \n",
    "            user_ids = batch['user_id'].to(device)\n",
    "            pos_item_ids = batch['pos_item_id'].to(device)\n",
    "            \n",
    "            # Get user and item embeddings\n",
    "            user_vec = model.user_vec(user_ids)\n",
    "            \n",
    "            # Get all item embeddings\n",
    "            all_item_ids = torch.arange(len(item_map), device=device)\n",
    "            all_item_vec = model.item_vec(all_item_ids)\n",
    "            \n",
    "            # Compute scores for all items\n",
    "            scores = torch.mm(user_vec, all_item_vec.T)\n",
    "            \n",
    "            # Get top-k recommendations\n",
    "            _, top_k_indices = torch.topk(scores, k=k, dim=1)\n",
    "            \n",
    "            # Check if positive items are in top-k\n",
    "            hits = (top_k_indices == pos_item_ids.unsqueeze(1)).any(dim=1)\n",
    "            recalls = hits.float().mean().item()\n",
    "            \n",
    "            all_recalls.append(recalls)\n",
    "            sample_count += len(user_ids)\n",
    "    \n",
    "    return np.mean(all_recalls) if all_recalls else 0.0\n",
    "\n",
    "# --- Training Loop ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING TWO-TOWER MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_recall = 0.0\n",
    "patience_counter = 0\n",
    "train_losses = []\n",
    "val_recalls = []\n",
    "\n",
    "for epoch in range(CFG['epochs']):\n",
    "    # Training\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    batch_count = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        user_ids = batch['user_id'].to(device)\n",
    "        pos_item_ids = batch['pos_item_id'].to(device)\n",
    "        neg_item_ids = batch['neg_item_ids'].to(device)\n",
    "        history_items = batch['history_items'].to(device)  # New field\n",
    "        \n",
    "        # Forward pass\n",
    "        pos_scores, neg_scores = model(user_ids, pos_item_ids, neg_item_ids)\n",
    "        \n",
    "        # Compute loss (same as before)\n",
    "        loss = in_batch_negative_loss(pos_scores, neg_scores)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient accumulation\n",
    "        if (batch_count + 1) % CFG['accum_steps'] == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        batch_count += 1\n",
    "    \n",
    "    # Average loss\n",
    "    avg_loss = epoch_loss / batch_count\n",
    "    train_losses.append(avg_loss)\n",
    "    \n",
    "    # Evaluation\n",
    "    val_recall = evaluate_recall_at_k(\n",
    "        model, \n",
    "        val_loader, \n",
    "        k=CFG['eval_topk'], \n",
    "        n_samples=CFG['eval_sample']\n",
    "    )\n",
    "    val_recalls.append(val_recall)\n",
    "    \n",
    "    # Print progress every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{CFG['epochs']}: Loss={avg_loss:.4f}, Recall@{CFG['eval_topk']}={val_recall:.4f}\")\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_recall)\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_recall > best_recall:\n",
    "        best_recall = val_recall\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), OUT_DIR / 'best_twotower_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= CFG['patience']:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nBest Recall@{CFG['eval_topk']}: {best_recall:.4f}\")\n",
    "\n",
    "# --- Load Best Model and Final Evaluation ---\n",
    "print(\"\\nLoading best model for final evaluation...\")\n",
    "model.load_state_dict(torch.load(OUT_DIR / 'best_twotower_model.pth'))\n",
    "\n",
    "# Final evaluation\n",
    "final_recall = evaluate_recall_at_k(model, val_loader, k=CFG['eval_topk'])\n",
    "print(f\"Final Recall@{CFG['eval_topk']}: {final_recall:.4f}\")\n",
    "\n",
    "# --- Save Embeddings ---\n",
    "print(\"\\nSaving embeddings...\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Save user embeddings\n",
    "    all_user_ids = torch.arange(len(customer_map), device=device)\n",
    "    user_embeddings = model.user_vec(all_user_ids).cpu().numpy()\n",
    "    np.save(OUT_DIR / 'user_embeddings.npy', user_embeddings)\n",
    "    \n",
    "    # Save item embeddings\n",
    "    all_item_ids = torch.arange(len(item_map), device=device)\n",
    "    item_embeddings = model.item_vec(all_item_ids).cpu().numpy()\n",
    "    np.save(OUT_DIR / 'item_embeddings.npy', item_embeddings)\n",
    "\n",
    "print(f\"Saved user embeddings: {user_embeddings.shape}\")\n",
    "print(f\"Saved item embeddings: {item_embeddings.shape}\")\n",
    "\n",
    "# --- Compare with Baselines ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARISON WITH BASELINES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get best baseline result\n",
    "best_baseline = max([\n",
    "    (model_name, results[f'Recall@{CFG[\"eval_topk\"]}'])\n",
    "    for model_name, results in baseline_results['held_out_interactions'].items()\n",
    "], key=lambda x: x[1])\n",
    "\n",
    "print(f\"Best baseline ({best_baseline[0]}): Recall@{CFG['eval_topk']} = {best_baseline[1]:.4f}\")\n",
    "print(f\"Two-Tower model: Recall@{CFG['eval_topk']} = {final_recall:.4f}\")\n",
    "\n",
    "improvement = ((final_recall - best_baseline[1]) / best_baseline[1]) * 100 if best_baseline[1] > 0 else 0\n",
    "print(f\"Improvement: {improvement:+.2f}%\")\n",
    "\n",
    "# --- Save Results ---\n",
    "results = {\n",
    "    'model_config': CFG,\n",
    "    'training_results': {\n",
    "        'best_recall': best_recall,\n",
    "        'final_recall': final_recall,\n",
    "        'train_losses': train_losses,\n",
    "        'val_recalls': val_recalls\n",
    "    },\n",
    "    'comparison': {\n",
    "        'best_baseline': {\n",
    "            'model': best_baseline[0],\n",
    "            'recall': best_baseline[1]\n",
    "        },\n",
    "        'two_tower_recall': final_recall,\n",
    "        'improvement_percent': improvement\n",
    "    },\n",
    "    'data_stats': baseline_results['data_stats']\n",
    "}\n",
    "\n",
    "with open(OUT_DIR / 'twotower_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\nSaved results to {OUT_DIR / 'twotower_results.json'}\")\n",
    "\n",
    "# --- Final Summary ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Dataset: Jarir Retail\")\n",
    "print(f\"Model: Two-Tower (Interaction-based)\")\n",
    "print(f\"Embedding dimension: {CFG['d_model']}\")\n",
    "print(f\"Training epochs: {len(train_losses)}\")\n",
    "print(f\"Best Recall@{CFG['eval_topk']}: {best_recall:.4f}\")\n",
    "print(f\"Final Recall@{CFG['eval_topk']}: {final_recall:.4f}\")\n",
    "print(f\"Improvement over best baseline: {improvement:+.2f}%\")\n",
    "\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"  - best_twotower_model.pth\")\n",
    "print(f\"  - user_embeddings.npy\")\n",
    "print(f\"  - item_embeddings.npy\")\n",
    "print(f\"  - twotower_results.json\")\n",
    "\n",
    "print(f\"\\nModel ready for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f614a24b-8a74-401e-87fc-7ae2c0ab115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1b23cc8-b8a7-421a-97d5-ed3e44fa8b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT_DIR: ../data/processed/jarir\n",
      "Device: cuda\n",
      "Train/Val/Test: (1108, 6) (169, 6) (160, 6)\n",
      "Items: 1735 Customers: 929\n",
      "Two-Tower embeddings loaded: (929, 256) (1735, 256)\n",
      "Price features loaded\n",
      "Candidates: (1108, 4) (169, 4) (160, 4)\n",
      "Shard dirs: ../data/processed/jarir/ranker_feats_train_shards ../data/processed/jarir/ranker_feats_val_shards ../data/processed/jarir/ranker_feats_test_shards\n",
      "\n",
      "==================================================\n",
      "TRAINING RANKER\n",
      "==================================================\n",
      "Epoch 01 | train BCE 0.4524 | val Recall@10 0.3846 | val NDCG@10 0.2482\n",
      "Epoch 02 | train BCE 0.2100 | val Recall@10 0.2544 | val NDCG@10 0.1739\n",
      "Epoch 03 | train BCE 0.1960 | val Recall@10 0.2604 | val NDCG@10 0.1768\n",
      "Epoch 04 | train BCE 0.1934 | val Recall@10 0.3550 | val NDCG@10 0.2304\n",
      "Epoch 05 | train BCE 0.1924 | val Recall@10 0.5089 | val NDCG@10 0.3884\n",
      "Epoch 06 | train BCE 0.1914 | val Recall@10 0.5917 | val NDCG@10 0.4415\n",
      "Epoch 07 | train BCE 0.1918 | val Recall@10 0.6272 | val NDCG@10 0.4659\n",
      "Epoch 08 | train BCE 0.1910 | val Recall@10 0.5325 | val NDCG@10 0.4107\n",
      "Epoch 09 | train BCE 0.1917 | val Recall@10 0.5325 | val NDCG@10 0.4049\n",
      "Epoch 10 | train BCE 0.1915 | val Recall@10 0.5385 | val NDCG@10 0.3810\n",
      "Epoch 11 | train BCE 0.1911 | val Recall@10 0.4675 | val NDCG@10 0.3579\n",
      "Epoch 12 | train BCE 0.1908 | val Recall@10 0.5030 | val NDCG@10 0.3739\n",
      "Early stopping on Recall@10.\n",
      "Best val Recall@10 = 0.6272\n",
      "\n",
      "==================================================\n",
      "FINAL EVALUATION\n",
      "==================================================\n",
      "TEST — Recall@10: 0.5625, NDCG@10: 0.4361\n",
      "\n",
      "==================================================\n",
      "COMPARISON WITH BASELINES\n",
      "==================================================\n",
      "Baseline Results (Held-out Interactions):\n",
      "  ItemKNN: {'Recall@5': 0.0, 'Recall@10': 0.005917159763313609, 'Recall@20': 0.005917159763313609}\n",
      "  UserKNN: {'Recall@5': 0.05917159763313609, 'Recall@10': 0.07100591715976332, 'Recall@20': 0.09467455621301775}\n",
      "  MatrixFactorization: {'Recall@5': 0.005917159763313609, 'Recall@10': 0.005917159763313609, 'Recall@20': 0.029585798816568046}\n",
      "  Popularity: {'Recall@5': 0.047337278106508875, 'Recall@10': 0.10650887573964497, 'Recall@20': 0.14201183431952663}\n",
      "\n",
      "Best baseline (Popularity): Recall@10 = 0.1065\n",
      "Two-Stage Ranker: Recall@10 = 0.5625\n",
      "Improvement: +428.12%\n",
      "\n",
      "Saved results to ../data/processed/jarir/ranker_results.json\n",
      "\n",
      "==================================================\n",
      "FINAL SUMMARY\n",
      "==================================================\n",
      "Dataset: Jarir Retail\n",
      "Model: Two-Stage (Two-Tower + MLP Ranker)\n",
      "Embedding dimension: 256\n",
      "Ranker hidden size: 256\n",
      "Test Recall@10: 0.5625\n",
      "Test NDCG@10: 0.4361\n",
      "\n",
      "Files saved:\n",
      "  - ranker_best.pt\n",
      "  - ranker_results.json\n",
      "\n",
      "Model ready for inference!\n",
      "\n",
      "==================================================\n",
      "FEATURE IMPORTANCE\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 539\u001b[39m\n\u001b[32m    537\u001b[39m logits = model(Xb)\n\u001b[32m    538\u001b[39m loss = loss_fn(logits, yb)\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m loss.backward()\n\u001b[32m    541\u001b[39m \u001b[38;5;66;03m# Accumulate gradient magnitudes\u001b[39;00m\n\u001b[32m    542\u001b[39m feature_importance += Xb.grad.abs().mean(dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cs323/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m torch.autograd.backward(\n\u001b[32m    649\u001b[39m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs=inputs\n\u001b[32m    650\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cs323/lib/python3.11/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m _engine_run_backward(\n\u001b[32m    354\u001b[39m     tensors,\n\u001b[32m    355\u001b[39m     grad_tensors_,\n\u001b[32m    356\u001b[39m     retain_graph,\n\u001b[32m    357\u001b[39m     create_graph,\n\u001b[32m    358\u001b[39m     inputs,\n\u001b[32m    359\u001b[39m     allow_unreachable=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    360\u001b[39m     accumulate_grad=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    361\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cs323/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable._execution_engine.run_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    825\u001b[39m         t_outputs, *args, **kwargs\n\u001b[32m    826\u001b[39m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# --- 0) Config & Imports --------------------------------------------------------\n",
    "import os, json, math, time, gc, glob, bisect\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# Data paths\n",
    "OUT_DIR = Path('../data/processed/jarir/')\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n",
    "\n",
    "READ_KW  = dict(engine=\"fastparquet\")\n",
    "WRITE_KW = dict(engine=\"fastparquet\", index=False)\n",
    "\n",
    "CFG = {\n",
    "    # Retrieval\n",
    "    \"cand_topk\": 100,\n",
    "    \"cand_batch\": 4096,          # Candidate generation batch size\n",
    "    # Histories & features\n",
    "    \"hist_max\": 15,               # Reduced for Jarir (smaller sequences)\n",
    "    # Feature building\n",
    "    \"feat_batch_q\": 1024,        # queries per GPU batch when building features\n",
    "    \"shard_rows\": 1_000_000,     # approx rows per Parquet shard (features)\n",
    "    \"neg_per_query\": 20,         # keep 1 pos + N hard negatives per query\n",
    "    \"hard_negatives\": True,      # choose hardest by dot_uv; False=random\n",
    "    # Ranker\n",
    "    \"batch_size\": 2048,          # larger thanks to AMP\n",
    "    \"epochs\": 20,\n",
    "    \"patience\": 5,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"dropout\": 0.2,\n",
    "    \"hidden\": 256,               # Smaller for Jarir\n",
    "    \"eval_topk\": 10,\n",
    "    \"seed\": 42,\n",
    "    \"use_text\": False,           # No text embeddings for Jarir\n",
    "    # Two-Tower embeddings\n",
    "    \"embedding_dim\": 256,\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "torch.manual_seed(CFG[\"seed\"])\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(CFG[\"seed\"])\n",
    "\n",
    "# Load sequences\n",
    "seq_train = pd.read_parquet(OUT_DIR/'sequences_train.parquet', **READ_KW)\n",
    "seq_val   = pd.read_parquet(OUT_DIR/'sequences_val.parquet', **READ_KW)\n",
    "seq_test  = pd.read_parquet(OUT_DIR/'sequences_test.parquet', **READ_KW)\n",
    "print(\"Train/Val/Test:\", seq_train.shape, seq_val.shape, seq_test.shape)\n",
    "\n",
    "# Load item and customer maps\n",
    "item_map = pd.read_parquet(OUT_DIR/'item_id_map.parquet', **READ_KW)\n",
    "customer_map = pd.read_parquet(OUT_DIR/'customer_id_map.parquet', **READ_KW)\n",
    "print(\"Items:\", len(item_map), \"Customers:\", len(customer_map))\n",
    "\n",
    "# Popularity for features/fallback\n",
    "pop_counts = seq_train['pos_item_idx'].value_counts()\n",
    "pop_norm = (pop_counts - pop_counts.min()) / (pop_counts.max() - pop_counts.min() + 1e-9)\n",
    "\n",
    "# Load Two-Tower embeddings\n",
    "USER_EMB_PATH = OUT_DIR/'user_embeddings.npy'\n",
    "ITEM_EMB_PATH = OUT_DIR/'item_embeddings.npy'\n",
    "\n",
    "if USER_EMB_PATH.exists() and ITEM_EMB_PATH.exists():\n",
    "    USER_EMB = np.load(USER_EMB_PATH).astype('float32')\n",
    "    ITEM_EMB = np.load(ITEM_EMB_PATH).astype('float32')\n",
    "    print(\"Two-Tower embeddings loaded:\", USER_EMB.shape, ITEM_EMB.shape)\n",
    "else:\n",
    "    print(\"❌ Missing Two-Tower embeddings. Please run notebook 03 first.\")\n",
    "    # Create dummy embeddings for testing\n",
    "    n_users = len(customer_map)\n",
    "    n_items = len(item_map)\n",
    "    USER_EMB = np.random.randn(n_users, CFG[\"embedding_dim\"]).astype('float32')\n",
    "    ITEM_EMB = np.random.randn(n_items, CFG[\"embedding_dim\"]).astype('float32')\n",
    "    # Normalize\n",
    "    USER_EMB /= np.linalg.norm(USER_EMB, axis=1, keepdims=True)\n",
    "    ITEM_EMB /= np.linalg.norm(ITEM_EMB, axis=1, keepdims=True)\n",
    "    print(\"Using dummy embeddings for testing\")\n",
    "\n",
    "# GPU tensors for embeddings\n",
    "USER_EMB_T = torch.from_numpy(USER_EMB).to(device, non_blocking=True)\n",
    "ITEM_EMB_T = torch.from_numpy(ITEM_EMB).to(device, non_blocking=True)\n",
    "\n",
    "# Popularity tensor\n",
    "pop_vec = torch.zeros(len(item_map), dtype=torch.float32, device=device)\n",
    "pop_idx = torch.tensor(pop_counts.index.values, dtype=torch.long, device=device)\n",
    "pop_val = torch.tensor(pop_norm.loc[pop_counts.index].values, dtype=torch.float32, device=device)\n",
    "pop_vec[pop_idx] = pop_val\n",
    "\n",
    "# Load item metadata for additional features\n",
    "items_clean_path = OUT_DIR/'items_clean.parquet'\n",
    "price_z = None\n",
    "if items_clean_path.exists():\n",
    "    items_clean = pd.read_parquet(items_clean_path, **READ_KW)\n",
    "    if 'price_median' in items_clean.columns:\n",
    "        m = items_clean[['stock_code','price_median']].dropna()\n",
    "        # Map stock_code to item_idx\n",
    "        m = m.merge(item_map, on='stock_code', how='inner')\n",
    "        if len(m) > 0:\n",
    "            mu, sigma = m['price_median'].mean(), m['price_median'].std() + 1e-6\n",
    "            z = ((m['price_median'] - mu) / sigma).astype(float)\n",
    "            price_z = torch.zeros(len(item_map), dtype=torch.float32, device=device)\n",
    "            ii = torch.tensor(m['item_idx'].astype(int).values, dtype=torch.long, device=device)\n",
    "            price_z[ii] = torch.tensor(z.values, dtype=torch.float32, device=device)\n",
    "            print(\"Price features loaded\")\n",
    "\n",
    "def parse_hist(s):\n",
    "    if not isinstance(s, str) or not s.strip():\n",
    "        return []\n",
    "    return [int(x) for x in s.strip().split()]\n",
    "\n",
    "# --- 1) Candidate Generation using Two-Tower Embeddings ---\n",
    "\n",
    "@torch.no_grad()\n",
    "def user_vecs_from_hist_batch(hist_tensor):\n",
    "    \"\"\"Compute user vectors from history using Two-Tower item embeddings\"\"\"\n",
    "    B, L = hist_tensor.shape\n",
    "    safe_idx = hist_tensor.clamp(min=0)  # replace -1 with 0 for gather\n",
    "    H = ITEM_EMB_T.index_select(0, safe_idx.view(-1)).view(B, L, -1)  # [B,L,d]\n",
    "    mask = (hist_tensor >= 0).float().unsqueeze(-1)                    # [B,L,1]\n",
    "    U = (H * mask).sum(1) / mask.sum(1).clamp_min(1e-6)                # [B,d]\n",
    "    U = F.normalize(U, dim=-1)\n",
    "    return U\n",
    "\n",
    "def build_hist_tensor(series, L):\n",
    "    \"\"\"Build history tensor from string series\"\"\"\n",
    "    B = len(series)\n",
    "    H = torch.full((B, L), -1, dtype=torch.long)\n",
    "    for i, s in enumerate(series):\n",
    "        h = parse_hist(s)\n",
    "        if len(h) > L: h = h[-L:]\n",
    "        if h:\n",
    "            H[i, -len(h):] = torch.tensor(h, dtype=torch.long)\n",
    "    return H\n",
    "\n",
    "def gen_candidates_gpu(df, topk=100, batch_q=4096):\n",
    "    \"\"\"Generate candidates using Two-Tower embeddings\"\"\"\n",
    "    hist_series = df['history_idx'].astype(str).tolist()\n",
    "    H = build_hist_tensor(hist_series, CFG[\"hist_max\"])  # CPU\n",
    "    U_chunks = []\n",
    "    for i in range(0, H.size(0), batch_q):\n",
    "        Ub = user_vecs_from_hist_batch(H[i:i+batch_q].to(device))\n",
    "        U_chunks.append(Ub.detach().cpu())\n",
    "    U = torch.cat(U_chunks, 0).numpy().astype('float32')\n",
    "\n",
    "    # Compute similarities with all items\n",
    "    with torch.no_grad():\n",
    "        U_tensor = torch.from_numpy(U).to(device)\n",
    "        sims = U_tensor @ ITEM_EMB_T.t()\n",
    "        _, top_k_indices = torch.topk(sims, k=topk, dim=1)\n",
    "        I_full = top_k_indices.cpu().numpy().astype('int32')\n",
    "\n",
    "    pos_list = df['pos_item_idx'].astype(int).tolist()\n",
    "    ts_list  = df['ts'].astype(str).tolist() if 'ts' in df.columns else ['']*len(pos_list)\n",
    "    rows = []\n",
    "    for pos, cand_idx, ts, h_s in zip(pos_list, I_full, ts_list, hist_series):\n",
    "        cand = cand_idx.tolist()\n",
    "        if pos not in cand:\n",
    "            cand[-1] = int(pos)\n",
    "        rows.append((h_s, int(pos), \" \".join(map(str,cand)), ts))\n",
    "    return pd.DataFrame(rows, columns=['history_idx','pos_item_idx','cands','ts'])\n",
    "\n",
    "# Build & save candidates if missing\n",
    "CAND_TRAIN_PATH = OUT_DIR/'candidates_train.parquet'\n",
    "CAND_VAL_PATH   = OUT_DIR/'candidates_val.parquet'\n",
    "CAND_TEST_PATH  = OUT_DIR/'candidates_test.parquet'\n",
    "\n",
    "if not (CAND_TRAIN_PATH.exists() and CAND_VAL_PATH.exists() and CAND_TEST_PATH.exists()):\n",
    "    print(\"Generating training candidates (GPU)...\")\n",
    "    gen_candidates_gpu(seq_train, topk=CFG[\"cand_topk\"], batch_q=CFG[\"cand_batch\"]).to_parquet(CAND_TRAIN_PATH, **WRITE_KW)\n",
    "    print(\"Generating validation candidates (GPU)...\")\n",
    "    gen_candidates_gpu(seq_val,   topk=CFG[\"cand_topk\"], batch_q=CFG[\"cand_batch\"]).to_parquet(CAND_VAL_PATH, **WRITE_KW)\n",
    "    print(\"Generating test candidates (GPU)...\")\n",
    "    gen_candidates_gpu(seq_test,  topk=CFG[\"cand_topk\"], batch_q=CFG[\"cand_batch\"]).to_parquet(CAND_TEST_PATH, **WRITE_KW)\n",
    "\n",
    "cand_train = pd.read_parquet(CAND_TRAIN_PATH, **READ_KW)\n",
    "cand_val   = pd.read_parquet(CAND_VAL_PATH, **READ_KW)\n",
    "cand_test  = pd.read_parquet(CAND_TEST_PATH, **READ_KW)\n",
    "print(\"Candidates:\", cand_train.shape, cand_val.shape, cand_test.shape)\n",
    "\n",
    "# --- 2) Feature Engineering on GPU (sharded) ---\n",
    "\n",
    "def _pack_batch_features(Ub, Hb, Cb, Pb):\n",
    "    \"\"\"Pack features for a batch of candidates\"\"\"\n",
    "    B, d = Ub.shape\n",
    "    K = Cb.size(1)\n",
    "    L = Hb.size(1)\n",
    "    \n",
    "    # Candidate item vectors\n",
    "    Vc = ITEM_EMB_T.index_select(0, Cb.view(-1)).view(B, K, d)\n",
    "    \n",
    "    # dot(u,v) - similarity between user and candidate\n",
    "    dot_uv = (Ub.unsqueeze(1) * Vc).sum(-1)                        # [B,K]\n",
    "    \n",
    "    # Max sim to recent history\n",
    "    safe_hist = Hb.clamp(min=0)\n",
    "    Hvec = ITEM_EMB_T.index_select(0, safe_hist.view(-1)).view(B, L, d)\n",
    "    Hvec = F.normalize(Hvec, dim=-1); Vc_n = F.normalize(Vc, dim=-1)\n",
    "    sims = torch.matmul(Hvec, Vc_n.transpose(1,2))                  # [B,L,K]\n",
    "    maskL = (Hb >= 0).unsqueeze(-1).float()\n",
    "    sims = sims + (maskL - 1.0) * 1e9\n",
    "    max_sim_recent = sims.max(dim=1).values                         # [B,K]\n",
    "    \n",
    "    # popularity & history length\n",
    "    pop = pop_vec.index_select(0, Cb.view(-1)).view(B, K)\n",
    "    hlen = (Hb >= 0).float().sum(1) / float(CFG[\"hist_max\"])\n",
    "    hlen = hlen.unsqueeze(1).expand(B, K)\n",
    "    \n",
    "    # price_z (if available)\n",
    "    if isinstance(price_z, torch.Tensor):\n",
    "        price = price_z.index_select(0, Cb.view(-1)).view(B, K)\n",
    "    else:\n",
    "        price = torch.zeros((B, K), device=Ub.device)\n",
    "    \n",
    "    # labels\n",
    "    labels = (Cb == Pb.view(-1,1)).float()\n",
    "    \n",
    "    return {\"dot_uv\": dot_uv, \"max_sim_recent\": max_sim_recent, \"pop\": pop,\n",
    "            \"hist_len\": hlen, \"price_z\": price, \"label\": labels, \"item_idx\": Cb.float()}\n",
    "\n",
    "def _select_negatives(feats):\n",
    "    \"\"\"Keep 1 positive + N negatives per query if configured\"\"\"\n",
    "    if CFG[\"neg_per_query\"] is None:\n",
    "        return feats\n",
    "    B, K = feats[\"label\"].shape\n",
    "    pos_col = torch.argmax(feats[\"label\"], dim=1, keepdim=True)     # [B,1]\n",
    "    if CFG[\"hard_negatives\"]:\n",
    "        neg_scores = feats[\"dot_uv\"].clone()\n",
    "        neg_scores.scatter_(1, pos_col, -1e9)\n",
    "        _, neg_idx = torch.topk(neg_scores, k=min(CFG[\"neg_per_query\"], K-1), dim=1)\n",
    "    else:\n",
    "        rnd = torch.rand_like(feats[\"dot_uv\"])\n",
    "        rnd.scatter_(1, pos_col, 1e9)\n",
    "        _, neg_idx = torch.topk(-rnd, k=min(CFG[\"neg_per_query\"], K-1), dim=1)\n",
    "    keep_cols = torch.cat([pos_col, neg_idx], dim=1)                # [B,1+N]\n",
    "    for k in [\"dot_uv\",\"max_sim_recent\",\"pop\",\"hist_len\",\"price_z\",\"label\",\"item_idx\"]:\n",
    "        feats[k] = torch.gather(feats[k], 1, keep_cols)\n",
    "    return feats\n",
    "\n",
    "def build_feats_gpu_sharded(cand_df, split_name):\n",
    "    \"\"\"Build features on GPU and save to sharded Parquet files\"\"\"\n",
    "    N = len(cand_df)\n",
    "    L = CFG[\"hist_max\"]\n",
    "    bq = CFG[\"feat_batch_q\"]\n",
    "    out_dir = OUT_DIR / f\"ranker_feats_{split_name}_shards\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def write_shard(idx, feats_dict):\n",
    "        cpu = {k: v.detach().float().view(-1).to('cpu').numpy() for k,v in feats_dict.items()}\n",
    "        df = pd.DataFrame(cpu); df['item_idx'] = df['item_idx'].astype(np.int32)\n",
    "        df.to_parquet(out_dir / f\"part_{idx:03d}.parquet\", **WRITE_KW)\n",
    "\n",
    "    hist_series = cand_df['history_idx'].astype(str).tolist()\n",
    "    pos_list = cand_df['pos_item_idx'].astype(int).tolist()\n",
    "    cands_series = cand_df['cands'].astype(str).tolist()\n",
    "\n",
    "    rows_written = 0; shard_idx = 0; buf = None\n",
    "    for i in range(0, N, bq):\n",
    "        H = build_hist_tensor(hist_series[i:i+bq], L).to(device, non_blocking=True)\n",
    "        P = torch.tensor(pos_list[i:i+bq], dtype=torch.long, device=device)\n",
    "        C = torch.tensor([[int(x) for x in s.split()] for s in cands_series[i:i+bq]],\n",
    "                         dtype=torch.long, device=device)\n",
    "        U = user_vecs_from_hist_batch(H)\n",
    "        feats = _pack_batch_features(U, H, C, P)\n",
    "        feats = _select_negatives(feats)\n",
    "\n",
    "        if buf is None:\n",
    "            buf = {k: v.detach().clone() for k,v in feats.items()}\n",
    "        else:\n",
    "            for k in buf.keys():\n",
    "                buf[k] = torch.cat([buf[k], feats[k]], dim=0)\n",
    "\n",
    "        rows_in_buf = int(buf[\"label\"].numel())\n",
    "        if rows_in_buf >= CFG[\"shard_rows\"]:\n",
    "            write_shard(shard_idx, buf); shard_idx += 1\n",
    "            for k in list(buf.keys()): del buf[k]\n",
    "            buf = None; torch.cuda.empty_cache()\n",
    "\n",
    "        rows_written += int(feats[\"label\"].numel())\n",
    "        if (i//bq) % 10 == 0:\n",
    "            print(f\"[{split_name}] Built ~{rows_written/1e6:.2f}M rows...\")\n",
    "\n",
    "    if buf is not None:\n",
    "        write_shard(shard_idx, buf); shard_idx += 1\n",
    "        for k in list(buf.keys()): del buf[k]\n",
    "        buf = None; torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"[{split_name}] Done. Rows ~{rows_written:,}. Shards -> {out_dir}\")\n",
    "    return out_dir\n",
    "\n",
    "# Build shards if missing\n",
    "train_shards_dir = OUT_DIR / \"ranker_feats_train_shards\"\n",
    "val_shards_dir   = OUT_DIR / \"ranker_feats_val_shards\"\n",
    "test_shards_dir  = OUT_DIR / \"ranker_feats_test_shards\"\n",
    "\n",
    "if not train_shards_dir.exists():\n",
    "    train_shards_dir = build_feats_gpu_sharded(cand_train, \"train\")\n",
    "if not val_shards_dir.exists():\n",
    "    val_shards_dir = build_feats_gpu_sharded(cand_val, \"val\")\n",
    "if not test_shards_dir.exists():\n",
    "    test_shards_dir = build_feats_gpu_sharded(cand_test, \"test\")\n",
    "\n",
    "print(\"Shard dirs:\", train_shards_dir, val_shards_dir, test_shards_dir)\n",
    "\n",
    "# --- 3) Ranker Model ---\n",
    "\n",
    "RANKER_COLS = [\"dot_uv\",\"max_sim_recent\",\"pop\",\"hist_len\",\"price_z\"]\n",
    "\n",
    "def shard_batches(files, batch_size):\n",
    "    \"\"\"Generate batches from sharded Parquet files\"\"\"\n",
    "    for f in sorted(glob.glob(str(Path(files)/\"part_*.parquet\")) if isinstance(files, (str, Path)) else files):\n",
    "        df = pd.read_parquet(f, engine=\"fastparquet\", columns=RANKER_COLS+[\"label\"])\n",
    "\n",
    "        # Build tensors without non_blocking, then .to(device, non_blocking=True)\n",
    "        X_np = df[RANKER_COLS].to_numpy(dtype='float32', copy=False)\n",
    "        y_np = df[\"label\"].to_numpy(dtype='float32', copy=False)\n",
    "        X = torch.from_numpy(X_np).to(device, non_blocking=True)\n",
    "        y = torch.from_numpy(y_np).to(device, non_blocking=True)\n",
    "\n",
    "        perm = torch.randperm(X.size(0), device=device)\n",
    "        for i in range(0, X.size(0), batch_size):\n",
    "            idx = perm[i:i+batch_size]\n",
    "            yield X[idx], y[idx]\n",
    "\n",
    "        del X, y, df\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "class RankerMLP(nn.Module):\n",
    "    \"\"\"MLP ranker for candidate re-ranking\"\"\"\n",
    "    def __init__(self, d_in, hidden=256, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_in, hidden), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, hidden//2), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden//2, 1)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x).squeeze(-1)\n",
    "\n",
    "model = RankerMLP(len(RANKER_COLS), hidden=CFG[\"hidden\"], dropout=CFG[\"dropout\"]).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "use_amp = (device.type == \"cuda\")\n",
    "amp_device = \"cuda\" if use_amp else \"cpu\"\n",
    "\n",
    "# GradScaler for mixed precision\n",
    "scaler = torch.amp.GradScaler(amp_device, enabled=use_amp)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# --- 4) Training & Evaluation ---\n",
    "\n",
    "def recall_at_k(preds, truth): \n",
    "    return float(truth in preds)\n",
    "\n",
    "def ndcg_at_k(preds, truth):\n",
    "    try:\n",
    "        r = preds.index(truth) + 1; return 1.0 / math.log2(r + 1.0)\n",
    "    except ValueError: \n",
    "        return 0.0\n",
    "\n",
    "@torch.no_grad()\n",
    "def rerank_one_batch(cand_df_slice):\n",
    "    \"\"\"Re-rank candidates for one batch\"\"\"\n",
    "    H = build_hist_tensor(cand_df_slice['history_idx'].astype(str).tolist(), CFG[\"hist_max\"]).to(device)\n",
    "    P = torch.tensor(cand_df_slice['pos_item_idx'].astype(int).tolist(), dtype=torch.long, device=device)\n",
    "    C = torch.tensor([[int(x) for x in s.split()] for s in cand_df_slice['cands'].astype(str).tolist()],\n",
    "                     dtype=torch.long, device=device)\n",
    "    U = user_vecs_from_hist_batch(H)\n",
    "    feats = _pack_batch_features(U, H, C, P)\n",
    "    # No negative subsampling at inference: rank all provided candidates\n",
    "    X = torch.stack([feats[c] for c in RANKER_COLS], dim=-1) # [B,K,5]\n",
    "    scores = model(X.view(-1, len(RANKER_COLS))).view(X.size(0), X.size(1))\n",
    "    topk = min(CFG[\"eval_topk\"], C.size(1))\n",
    "    vals, idx = torch.topk(scores, k=topk, dim=1)\n",
    "    reranked = [C[i][idx[i]].tolist() for i in range(C.size(0))]\n",
    "    return reranked\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_reranked(cand_df, split=\"val\"):\n",
    "    \"\"\"Evaluate re-ranked candidates\"\"\"\n",
    "    model.eval()\n",
    "    hits = 0; ndcgs = 0.0; tot = 0\n",
    "    B = 1024\n",
    "    for i in range(0, len(cand_df), B):\n",
    "        batch_df = cand_df.iloc[i:i+B]\n",
    "        reranked = rerank_one_batch(batch_df)\n",
    "        for pos, rr in zip(batch_df['pos_item_idx'].tolist(), reranked):\n",
    "            pos = int(pos)\n",
    "            hits += float(pos in rr)\n",
    "            if pos in rr:\n",
    "                r = rr.index(pos) + 1\n",
    "                ndcgs += 1.0 / math.log2(r + 1.0)\n",
    "            tot += 1\n",
    "    return hits/max(1,tot), ndcgs/max(1,tot)\n",
    "\n",
    "def train_ranker():\n",
    "    \"\"\"Train the ranker model\"\"\"\n",
    "    best_recall = -1.0; bad = 0\n",
    "    for ep in range(1, CFG[\"epochs\"]+1):\n",
    "        model.train()\n",
    "        total_loss = 0.0; nobs = 0\n",
    "        for Xb, yb in shard_batches(train_shards_dir, CFG[\"batch_size\"]):\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast(amp_device, enabled=use_amp, dtype=torch.float16):\n",
    "                logits = model(Xb)\n",
    "                loss = loss_fn(logits, yb)\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(opt); scaler.update()\n",
    "            total_loss += float(loss.item()) * yb.numel()\n",
    "            nobs += yb.numel()\n",
    "\n",
    "        # Evaluate every epoch\n",
    "        val_recall, val_ndcg = eval_reranked(cand_val, split=\"val\")\n",
    "        print(f\"Epoch {ep:02d} | train BCE {total_loss/max(1,nobs):.4f} | \"\n",
    "              f\"val Recall@{CFG['eval_topk']} {val_recall:.4f} | val NDCG@{CFG['eval_topk']} {val_ndcg:.4f}\")\n",
    "        if val_recall > best_recall + 1e-4:\n",
    "            best_recall, bad = val_recall, 0\n",
    "            torch.save(model.state_dict(), OUT_DIR/'ranker_best.pt')\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= CFG[\"patience\"]:\n",
    "                print(\"Early stopping on Recall@10.\"); break\n",
    "    print(\"Best val Recall@{} = {:.4f}\".format(CFG[\"eval_topk\"], best_recall))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING RANKER\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "train_ranker()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load best model and evaluate\n",
    "model.load_state_dict(torch.load(OUT_DIR/'ranker_best.pt', map_location=device, weights_only=True))\n",
    "test_recall, test_ndcg = eval_reranked(cand_test, split=\"test\")\n",
    "print(\"TEST — Recall@{}: {:.4f}, NDCG@{}: {:.4f}\".format(CFG[\"eval_topk\"], test_recall, CFG[\"eval_topk\"], test_ndcg))\n",
    "\n",
    "# --- 5) Comparison with Baselines ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARISON WITH BASELINES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load baseline results if available\n",
    "baseline_results_path = OUT_DIR / 'baseline_results.json'\n",
    "if baseline_results_path.exists():\n",
    "    with open(baseline_results_path, 'r') as f:\n",
    "        baseline_results = json.load(f)\n",
    "    \n",
    "    print(\"Baseline Results (Held-out Interactions):\")\n",
    "    for model_name, results in baseline_results['held_out_interactions'].items():\n",
    "        print(f\"  {model_name}: {results}\")\n",
    "    \n",
    "    # Get best baseline\n",
    "    best_baseline = max([\n",
    "        (model_name, results[f'Recall@{CFG[\"eval_topk\"]}'])\n",
    "        for model_name, results in baseline_results['held_out_interactions'].items()\n",
    "    ], key=lambda x: x[1])\n",
    "    \n",
    "    print(f\"\\nBest baseline ({best_baseline[0]}): Recall@{CFG['eval_topk']} = {best_baseline[1]:.4f}\")\n",
    "    print(f\"Two-Stage Ranker: Recall@{CFG['eval_topk']} = {test_recall:.4f}\")\n",
    "    \n",
    "    improvement = ((test_recall - best_baseline[1]) / best_baseline[1]) * 100 if best_baseline[1] > 0 else 0\n",
    "    print(f\"Improvement: {improvement:+.2f}%\")\n",
    "else:\n",
    "    print(\"No baseline results found for comparison\")\n",
    "\n",
    "# --- 6) Save Results ---\n",
    "\n",
    "results = {\n",
    "    'model_config': CFG,\n",
    "    'evaluation_results': {\n",
    "        'test_recall': test_recall,\n",
    "        'test_ndcg': test_ndcg,\n",
    "        'eval_topk': CFG['eval_topk']\n",
    "    },\n",
    "    'data_stats': {\n",
    "        'n_users': len(customer_map),\n",
    "        'n_items': len(item_map),\n",
    "        'train_sequences': len(seq_train),\n",
    "        'val_sequences': len(seq_val),\n",
    "        'test_sequences': len(seq_test)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(OUT_DIR / 'ranker_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\nSaved results to {OUT_DIR / 'ranker_results.json'}\")\n",
    "\n",
    "# --- 7) Final Summary ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Dataset: Jarir Retail\")\n",
    "print(f\"Model: Two-Stage (Two-Tower + MLP Ranker)\")\n",
    "print(f\"Embedding dimension: {CFG['embedding_dim']}\")\n",
    "print(f\"Ranker hidden size: {CFG['hidden']}\")\n",
    "print(f\"Test Recall@{CFG['eval_topk']}: {test_recall:.4f}\")\n",
    "print(f\"Test NDCG@{CFG['eval_topk']}: {test_ndcg:.4f}\")\n",
    "\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"  - ranker_best.pt\")\n",
    "print(f\"  - ranker_results.json\")\n",
    "\n",
    "print(f\"\\nModel ready for inference!\")\n",
    "\n",
    "# --- 8) Optional: Feature Importance Analysis ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FEATURE IMPORTANCE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Analyze feature importance by computing gradients\n",
    "model.eval()\n",
    "feature_importance = torch.zeros(len(RANKER_COLS), device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Sample a batch from validation\n",
    "    for Xb, yb in shard_batches(val_shards_dir, 1024):\n",
    "        Xb.requires_grad_(True)\n",
    "        logits = model(Xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Accumulate gradient magnitudes\n",
    "        feature_importance += Xb.grad.abs().mean(dim=0)\n",
    "        break\n",
    "\n",
    "feature_importance = feature_importance.cpu().numpy()\n",
    "feature_names = RANKER_COLS\n",
    "\n",
    "print(\"Feature Importance (gradient magnitude):\")\n",
    "for name, importance in zip(feature_names, feature_importance):\n",
    "    print(f\"  {name}: {importance:.4f}\")\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(feature_names, feature_importance)\n",
    "plt.title('Feature Importance in Ranker')\n",
    "plt.ylabel('Gradient Magnitude')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383b5495-7c5e-4d57-93b9-e9629482ecd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
