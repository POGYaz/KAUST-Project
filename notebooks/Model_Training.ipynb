{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ALS Model Training and Evaluation\n",
        "\n",
        "This notebook trains Alternating Least Squares (ALS) recommendation models using the engineered interaction matrices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add src to path\n",
        "ROOT = Path.cwd().parent\n",
        "sys.path.append(str(ROOT / \"src\"))\n",
        "\n",
        "from models.interaction_matrix import InteractionMatrixBuilder\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Load Interaction Matrices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-27 09:51:11,437 — INFO — Loading confidence matrix from c:\\KAUST-Project\\data\\matrices\\confidence_matrix.npz\n",
            "2025-07-27 09:51:11,445 — INFO — Loading quantity matrix from c:\\KAUST-Project\\data\\matrices\\quantity_matrix.npz\n",
            "2025-07-27 09:51:11,449 — INFO — Loading binary matrix from c:\\KAUST-Project\\data\\matrices\\binary_matrix.npz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using features file: c:\\KAUST-Project\\data\\features\\features_table_v2.csv\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Object arrays cannot be loaded when allow_pickle=False",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Load encoders\u001b[39;00m\n\u001b[32m     21\u001b[39m encoders = np.load(matrices_dir / \u001b[33m\"\u001b[39m\u001b[33mencoders.npz\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m user_classes = \u001b[43mencoders\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muser_classes\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     23\u001b[39m item_classes = encoders[\u001b[33m'\u001b[39m\u001b[33mitem_classes\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMatrix shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfidence_matrix.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\numpy\\lib\\_npyio_impl.py:254\u001b[39m, in \u001b[36mNpzFile.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m magic == \u001b[38;5;28mformat\u001b[39m.MAGIC_PREFIX:\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mbytes\u001b[39m = \u001b[38;5;28mself\u001b[39m.zip.open(key)\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.zip.read(key)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\numpy\\lib\\format.py:815\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype.hasobject:\n\u001b[32m    813\u001b[39m     \u001b[38;5;66;03m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n\u001b[32m    814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mObject arrays cannot be loaded when \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    816\u001b[39m                          \u001b[33m\"\u001b[39m\u001b[33mallow_pickle=False\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    817\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pickle_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    818\u001b[39m         pickle_kwargs = {}\n",
            "\u001b[31mValueError\u001b[39m: Object arrays cannot be loaded when allow_pickle=False"
          ]
        }
      ],
      "source": [
        "# Check if features file exists and specify path explicitly\n",
        "features_path = ROOT / \"data\" / \"features\" / \"features_table_v2.csv\"\n",
        "if not features_path.exists():\n",
        "    features_path = ROOT / \"data\" / \"features\" / \"features_table.csv\"\n",
        "\n",
        "if not features_path.exists():\n",
        "    raise FileNotFoundError(f\"Features file not found. Checked: {features_path}\")\n",
        "\n",
        "print(f\"Using features file: {features_path}\")\n",
        "\n",
        "# Initialize matrix builder with explicit path\n",
        "builder = InteractionMatrixBuilder(features_path=str(features_path))\n",
        "\n",
        "# Load matrices\n",
        "matrices_dir = ROOT / \"data\" / \"matrices\"\n",
        "confidence_matrix = builder.load_matrix('confidence', matrices_dir)\n",
        "quantity_matrix = builder.load_matrix('quantity', matrices_dir)\n",
        "binary_matrix = builder.load_matrix('binary', matrices_dir)\n",
        "\n",
        "# Load encoders\n",
        "encoders = np.load(matrices_dir / \"encoders.npz\")\n",
        "user_classes = encoders['user_classes']\n",
        "item_classes = encoders['item_classes']\n",
        "\n",
        "print(f\"Matrix shape: {confidence_matrix.shape}\")\n",
        "print(f\"Users: {len(user_classes)}, Items: {len(item_classes)}\")\n",
        "print(f\"Interactions: {confidence_matrix.nnz:,}\")\n",
        "print(f\"Density: {confidence_matrix.nnz / (confidence_matrix.shape[0] * confidence_matrix.shape[1]) * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Install Required Libraries\n",
        "\n",
        "Run this cell if libraries are not installed:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment and run if needed\n",
        "!pip install implicit scikit-learn matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import implicit\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Train/Test Split Strategy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_train_test_split(matrix, test_ratio=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Create train/test split by randomly holding out interactions per user.\n",
        "    \"\"\"\n",
        "    np.random.seed(random_state)\n",
        "    train_matrix = matrix.copy()\n",
        "    test_interactions = []\n",
        "    \n",
        "    for user_id in range(matrix.shape[0]):\n",
        "        user_items = matrix.getrow(user_id).indices\n",
        "        if len(user_items) > 1:  # Only split if user has multiple interactions\n",
        "            n_test = max(1, int(len(user_items) * test_ratio))\n",
        "            test_items = np.random.choice(user_items, size=n_test, replace=False)\n",
        "            \n",
        "            for item_id in test_items:\n",
        "                test_interactions.append((user_id, item_id, matrix[user_id, item_id]))\n",
        "                train_matrix[user_id, item_id] = 0\n",
        "    \n",
        "    train_matrix.eliminate_zeros()\n",
        "    return train_matrix, test_interactions\n",
        "\n",
        "# Create splits\n",
        "train_matrix, test_interactions = create_train_test_split(confidence_matrix)\n",
        "\n",
        "print(f\"Train interactions: {train_matrix.nnz:,}\")\n",
        "print(f\"Test interactions: {len(test_interactions):,}\")\n",
        "print(f\"Split ratio: {len(test_interactions) / (train_matrix.nnz + len(test_interactions)):.1%}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Model Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train ALS model\n",
        "model = implicit.als.AlternatingLeastSquares(\n",
        "    factors=50,\n",
        "    regularization=0.1,\n",
        "    iterations=200,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit model (implicit expects item-user matrix)\n",
        "model.fit(train_matrix.T)\n",
        "\n",
        "print(\"Model training completed\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def precision_recall_at_k(model, test_interactions, train_matrix, k=10):\n",
        "    \"\"\"\n",
        "    Calculate Precision@K and Recall@K for the model.\n",
        "    \"\"\"\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    \n",
        "    # Group test interactions by user\n",
        "    user_test_items = {}\n",
        "    for user_id, item_id, rating in test_interactions:\n",
        "        if user_id not in user_test_items:\n",
        "            user_test_items[user_id] = []\n",
        "        user_test_items[user_id].append(item_id)\n",
        "    \n",
        "    for user_id, true_items in user_test_items.items():\n",
        "        # Get recommendations\n",
        "        recs = model.recommend(user_id, train_matrix[user_id], N=k, filter_already_liked_items=True)\n",
        "        recommended_items = [item_id for item_id, score in recs]\n",
        "        \n",
        "        # Calculate metrics\n",
        "        hits = len(set(recommended_items) & set(true_items))\n",
        "        precision = hits / len(recommended_items) if recommended_items else 0\n",
        "        recall = hits / len(true_items) if true_items else 0\n",
        "        \n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "    \n",
        "    return np.mean(precisions), np.mean(recalls)\n",
        "\n",
        "# Evaluate at different K values\n",
        "k_values = [5, 10, 20, 50]\n",
        "results = []\n",
        "\n",
        "for k in k_values:\n",
        "    precision, recall = precision_recall_at_k(model, test_interactions, train_matrix, k=k)\n",
        "    results.append({'K': k, 'Precision': precision, 'Recall': recall})\n",
        "    print(f\"K={k:2d}: Precision@K={precision:.4f}, Recall@K={recall:.4f}\")\n",
        "\n",
        "results_df = pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Hyperparameter Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different hyperparameter combinations\n",
        "param_grid = {\n",
        "    'factors': [25, 50, 100],\n",
        "    'regularization': [0.01, 0.1, 0.5],\n",
        "    'iterations': [15, 20, 30]\n",
        "}\n",
        "\n",
        "best_score = 0\n",
        "best_params = None\n",
        "tuning_results = []\n",
        "\n",
        "# Grid search (simplified - testing a subset)\n",
        "test_configs = [\n",
        "    {'factors': 25, 'regularization': 0.1, 'iterations': 15},\n",
        "    {'factors': 50, 'regularization': 0.1, 'iterations': 20},\n",
        "    {'factors': 100, 'regularization': 0.1, 'iterations': 20},\n",
        "    {'factors': 50, 'regularization': 0.01, 'iterations': 20},\n",
        "    {'factors': 50, 'regularization': 0.5, 'iterations': 20}\n",
        "]\n",
        "\n",
        "for params in test_configs:\n",
        "    # Train model with current parameters\n",
        "    temp_model = implicit.als.AlternatingLeastSquares(\n",
        "        factors=params['factors'],\n",
        "        regularization=params['regularization'],\n",
        "        iterations=params['iterations'],\n",
        "        random_state=42\n",
        "    )\n",
        "    temp_model.fit(train_matrix.T)\n",
        "    \n",
        "    # Evaluate\n",
        "    precision, recall = precision_recall_at_k(temp_model, test_interactions, train_matrix, k=10)\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    \n",
        "    result = {**params, 'Precision@10': precision, 'Recall@10': recall, 'F1@10': f1_score}\n",
        "    tuning_results.append(result)\n",
        "    \n",
        "    if f1_score > best_score:\n",
        "        best_score = f1_score\n",
        "        best_params = params\n",
        "        best_model = temp_model\n",
        "\n",
        "tuning_df = pd.DataFrame(tuning_results)\n",
        "print(\"Hyperparameter Tuning Results:\")\n",
        "print(tuning_df.round(4))\n",
        "print(f\"\\nBest parameters: {best_params}\")\n",
        "print(f\"Best F1@10 score: {best_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Generate Recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_recommendations_for_user(user_idx, model, matrix, encoders, n_recommendations=10):\n",
        "    \"\"\"\n",
        "    Get product recommendations for a specific user.\n",
        "    \"\"\"\n",
        "    user_id = encoders['user_classes'][user_idx]\n",
        "    \n",
        "    # Get recommendations\n",
        "    recs = model.recommend(user_idx, matrix[user_idx], N=n_recommendations, filter_already_liked_items=True)\n",
        "    \n",
        "    recommendations = []\n",
        "    for item_idx, score in recs:\n",
        "        sku = encoders['item_classes'][item_idx]\n",
        "        recommendations.append({\n",
        "            'CustomerID': user_id,\n",
        "            'SKU': sku,\n",
        "            'Score': score,\n",
        "            'Rank': len(recommendations) + 1\n",
        "        })\n",
        "    \n",
        "    return recommendations\n",
        "\n",
        "# Generate recommendations for first 5 users\n",
        "sample_recommendations = []\n",
        "for user_idx in range(5):\n",
        "    user_recs = get_recommendations_for_user(user_idx, best_model, train_matrix, encoders)\n",
        "    sample_recommendations.extend(user_recs)\n",
        "\n",
        "sample_df = pd.DataFrame(sample_recommendations)\n",
        "print(\"Sample Recommendations:\")\n",
        "print(sample_df.head(20))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Model Analysis and Insights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze user and item factors\n",
        "user_factors = best_model.user_factors\n",
        "item_factors = best_model.item_factors\n",
        "\n",
        "print(f\"User factors shape: {user_factors.shape}\")\n",
        "print(f\"Item factors shape: {item_factors.shape}\")\n",
        "\n",
        "# Plot factor distributions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# User factors distribution\n",
        "axes[0].hist(user_factors.flatten(), bins=50, alpha=0.7)\n",
        "axes[0].set_title('Distribution of User Factors')\n",
        "axes[0].set_xlabel('Factor Value')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "\n",
        "# Item factors distribution\n",
        "axes[1].hist(item_factors.flatten(), bins=50, alpha=0.7)\n",
        "axes[1].set_title('Distribution of Item Factors')\n",
        "axes[1].set_xlabel('Factor Value')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Most popular items (by interactions)\n",
        "item_popularity = np.array(confidence_matrix.sum(axis=0)).flatten()\n",
        "popular_items_idx = np.argsort(item_popularity)[::-1][:10]\n",
        "\n",
        "print(\"Top 10 Most Popular Items:\")\n",
        "for i, item_idx in enumerate(popular_items_idx):\n",
        "    sku = item_classes[item_idx]\n",
        "    interactions = item_popularity[item_idx]\n",
        "    print(f\"{i+1:2d}. SKU {sku}: {interactions:.0f} interactions\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Model Comparison with Different Matrices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare performance across different interaction matrices\n",
        "matrices_to_test = {\n",
        "    'Confidence': confidence_matrix,\n",
        "    'Quantity': quantity_matrix,\n",
        "    'Binary': binary_matrix\n",
        "}\n",
        "\n",
        "matrix_comparison = []\n",
        "\n",
        "for matrix_name, matrix in matrices_to_test.items():\n",
        "    # Create train/test split for this matrix\n",
        "    train_mat, test_int = create_train_test_split(matrix)\n",
        "    \n",
        "    # Train model\n",
        "    temp_model = implicit.als.AlternatingLeastSquares(\n",
        "        factors=best_params['factors'],\n",
        "        regularization=best_params['regularization'],\n",
        "        iterations=best_params['iterations'],\n",
        "        random_state=42\n",
        "    )\n",
        "    temp_model.fit(train_mat.T)\n",
        "    \n",
        "    # Evaluate\n",
        "    precision, recall = precision_recall_at_k(temp_model, test_int, train_mat, k=10)\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    \n",
        "    matrix_comparison.append({\n",
        "        'Matrix': matrix_name,\n",
        "        'Precision@10': precision,\n",
        "        'Recall@10': recall,\n",
        "        'F1@10': f1_score\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(matrix_comparison)\n",
        "print(\"Matrix Comparison Results:\")\n",
        "print(comparison_df.round(4))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Save Trained Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best model and metadata\n",
        "models_dir = ROOT / \"models\" / \"saved_models\"\n",
        "models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "model_artifacts = {\n",
        "    'model': best_model,\n",
        "    'best_params': best_params,\n",
        "    'user_encoder_classes': user_classes,\n",
        "    'item_encoder_classes': item_classes,\n",
        "    'evaluation_results': results_df,\n",
        "    'hyperparameter_results': tuning_df,\n",
        "    'matrix_comparison': comparison_df,\n",
        "    'train_matrix_shape': train_matrix.shape,\n",
        "    'test_interactions_count': len(test_interactions)\n",
        "}\n",
        "\n",
        "# Save model artifacts\n",
        "with open(models_dir / \"als_model_artifacts.pkl\", 'wb') as f:\n",
        "    pickle.dump(model_artifacts, f)\n",
        "\n",
        "print(f\"Model saved to {models_dir / 'als_model_artifacts.pkl'}\")\n",
        "print(f\"Model can be loaded using: pickle.load(open(path, 'rb'))\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"MODEL TRAINING SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Dataset: {confidence_matrix.shape[0]} users × {confidence_matrix.shape[1]} items\")\n",
        "print(f\"Total interactions: {confidence_matrix.nnz:,}\")\n",
        "print(f\"Matrix density: {confidence_matrix.nnz / (confidence_matrix.shape[0] * confidence_matrix.shape[1]) * 100:.2f}%\")\n",
        "print()\n",
        "print(\"Best Model Configuration:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "print()\n",
        "print(\"Performance (Best Matrix):\")\n",
        "best_matrix_result = comparison_df.loc[comparison_df['F1@10'].idxmax()]\n",
        "print(f\"  Matrix Type: {best_matrix_result['Matrix']}\")\n",
        "print(f\"  Precision@10: {best_matrix_result['Precision@10']:.4f}\")\n",
        "print(f\"  Recall@10: {best_matrix_result['Recall@10']:.4f}\")\n",
        "print(f\"  F1@10: {best_matrix_result['F1@10']:.4f}\")\n",
        "print()\n",
        "print(f\"Model artifacts saved to: {models_dir / 'als_model_artifacts.pkl'}\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
